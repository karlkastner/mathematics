\documentclass[11pt,twoside,a4paper]{article}
%{book}

% This is an automatically generated file.
% Do not edit it.
% Changes to this file are not preserved!

\usepackage{tocloft}
\usepackage{hyperref}
\usepackage{listings}
\lstset{
basicstyle=\small\ttfamily,
columns=flexible,
breaklines=true
}
\setlength{\cftsubsecnumwidth}{3.5em}

\title{Manual for Package:
mathematics\protect\\Revision 25M
}
\author{Karl K\"astner}
%\date{}

\begin{document}

\maketitle

\tableofcontents

% licence
% abstract


\section{calendar}
\subsection{days\_per\_month}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{isnight}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{cast\_byte\_to\_integer}
${}$
\begin{lstlisting}
 cast byte to integer

\end{lstlisting}
\section{complex-analysis}
\begin{lstlisting}
operations on complex numbers


\end{lstlisting}
\subsection{complex\_exp\_product\_im\_im}
${}$
\begin{lstlisting}
  product of the imaginary part of two complex exponentials

 the product has two frequency components

 input :
 	c : complex amplitudes
	o : frequencies
 output :
	cp : amplitude of the product
	op : frequencies of the product

\end{lstlisting}
\subsection{complex\_exp\_product\_im\_re}
${}$
\begin{lstlisting}
  product of the imaginary part of one and the real part of a second
  complex exponential

 the product has two frequency components

 input :
 	c : complex amplitudes
	o : frequencies
 output :
	cp : amplitude of the product
	op : frequencies of the product

\end{lstlisting}
\subsection{complex\_exp\_product\_re\_im}
${}$
\begin{lstlisting}

 the product has two frequency components

  product of the imaginary part of one and the real part of a second
  complex exponential

 input :
 	c : complex amplitudes
	o : frequencies
 output :
	cp : amplitude of the product
	op : frequencies of the product

\end{lstlisting}
\subsection{complex\_exp\_product\_re\_re}
${}$
\begin{lstlisting}

  product of the real part of two complex exponentials

 re(c1 exp(io1x))*re(c2 exp(io2x)) = 
	1/2*(     real(c1*c2*exp(i*(n1+n2)*o*x)) ...                            
               + real(conj(c1)*c2*exp(i*(n2-n1)*o*x)) )

 the product has two frequency components

 input :
 	c : complex amplitudes
	o : frequencies
 output :
	cp : amplitude of the product
	op : frequencies of the product

\end{lstlisting}
\subsection{croots}
${}$
\begin{lstlisting}
 nth-roots of a complex number

 input:
 c : complex number
 n : order of root
     n must be rational, to obtain n solutions
     otherwise no finite set of solutions exists

 r : roots of the complex number

\end{lstlisting}
\subsection{root\_complex}
${}$
\begin{lstlisting}
 root of a complex number

\end{lstlisting}
\subsection{test\_imroots}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{derivation}
\begin{lstlisting}
derivation of several functions by means of symbolic computation


\end{lstlisting}
\subsection{derive\_acfar1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_ar1\_spectral\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_ar2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_arc\_length}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fourier\_power\_exp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_laplacian\_curvilinear}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_laplacian\_fourier\_piecewise\_linear}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_logtripdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_phase\_drift\_inv}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_smooth1d\_parametric}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_spectral\_density\_bandpass\_initial\_condition}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{derivation/master}
\subsection{derive\_bc\_one\_sided}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_convergence}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_error\_fdm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fdm\_poly}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fdm\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fdm\_taylor}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fdm\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fem\_2d\_mass}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fem\_error\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fem\_error\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_fem\_sym\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_grid\_constants}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_interpolation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_laplacian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_limit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_nc\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_nc\_1d\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_nc\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_nonuniform\_symmetric}
${}$
\begin{lstlisting}
%

\end{lstlisting}
\subsection{derive\_richardson}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_sum}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{nn}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_derive}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_derive\_fdm\_poly}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_filter}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{derivation}
\begin{lstlisting}
derivation of several functions by means of symbolic computation


\end{lstlisting}
\subsection{simplify\_atan}
${}$
\begin{lstlisting}
 symbolic simplification of the arcus tangent

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{entropy}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{finance}
\subsection{derive\_skewrnd\_walsh\_paramter}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbb\_geostd\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbb\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbb\_simulate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbb\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_bridge}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_cdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_fit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_fit\_old}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_geomean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_geostd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_inv}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_mean\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_median}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_moment2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_moment2par\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_simulate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_skewness}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_std\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gbm\_transform\_time\_step}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{put\_price\_black\_scholes}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewgbm\_simulate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewrnd\_walsh}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{finance/test}
\subsection{test\_gbm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_skewrnd\_walsh}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{fourier/@STFT}
\subsection{STFT}
${}$
\begin{lstlisting}
 class for short time fourier transform

 Note: the interval Ti should be set to at leat 2*max(T), as otherwise coefficients
       tend to oscillate in the presence of noise
 Note: for convenience, the independent variable is labeled as time (t),
       but the independent variable is arbitrary, so it works likewise in space

\end{lstlisting}
\subsection{itransform}
${}$
\begin{lstlisting}
 inverse of the short time fourier transform

\end{lstlisting}
\subsection{stft\_}
${}$
\begin{lstlisting}
 static wrapper for STFT

\end{lstlisting}
\subsection{stftmat}
${}$
\begin{lstlisting}
 transformation matrix for the short time fourier transform

\end{lstlisting}
\subsection{transform}
${}$
\begin{lstlisting}
 short time fourier transform

\end{lstlisting}
\section{fourier}
\begin{lstlisting}
support and analysis functions both for the discrete (fast) fourier transform (dft/fft)
and continuous fourier analysis (fourier series)


\end{lstlisting}
\subsection{amplitude\_from\_peak}
${}$
\begin{lstlisting}
 amplitude and standard deviation of the amplitude of a frequency component
 represented by a peak in the fourier domain
 input :
 h : peak height
 w : peak width at half height

 output:
 a : amplitude in real space
 s : standard deviation of the frequency (!)

\end{lstlisting}
\subsection{caesaro\_weight}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{dftmtx\_man}
${}$
\begin{lstlisting}
 fourier matrix in matlab style with a limited number of rows,
 columns of higher frequencies are omitted

 input :
 n  : number of samples
 nr : number of columns

 output :
 F : fourier matrix

\end{lstlisting}
\subsection{example\_fourier\_window}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fft2\_cartesian2radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fft\_man}
${}$
\begin{lstlisting}
 fast fourier transform for complex input data

 input:
 F : data in real space

 output :

 F : fourier transformation of F


\end{lstlisting}
\subsection{fft\_rotate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fftsmooth}
${}$
\begin{lstlisting}
 smooth the fourier transform and determine upper and lower bound confidence intervals

 input :
 f :
 sfunc  : a smoothing function (for example fir convolution with rectangular window)
          returns filtered (mean) value and normalized fir window
 nf     : window length
 nsigma : number of standard deviations for confidnce intervals


 output :
 ff : filtered fourier transform
 l : lower bound
 u : upper bound

\end{lstlisting}
\subsection{fix\_fourier}
${}$
\begin{lstlisting}
 fill gaps (missing data) by means of fourier extrapolation

 fix periodic data series with fourier interpolation
 longest gap should not exceed 1/2 of the shortest time span of interest (1/cutoff frequency)
  note: this limit equals the position of first side lobe of the ft of a rectangular window with gap length

\end{lstlisting}
\subsection{fourier\_2d\_padd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_2d\_quadrants}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_axis}
${}$
\begin{lstlisting}
 return axis of frequencies and periods for the discrete fourier transform
 as computed by fft (matlab-style)

 input:
 X : sample locations (equal interval)
 L : length of samples
 n : number of samples

 output :
 f    : frequencies
 T    : periods
 mask : mask for 1/2 of the fourier transform
        (as both halves are complex conjugates)
 N    : frequency id

\end{lstlisting}
\subsection{fourier\_axis\_2d}
${}$
\begin{lstlisting}
 function [fx, fy, fr, ft, Tx, Ty, mask, N] = fourier_axis_2d(L,n)

\end{lstlisting}
\subsection{fourier\_cesaro\_correction}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_coefficient\_piecewise\_linear}
${}$
\begin{lstlisting}
 fourier series coefficients of a piecewise linear function
 (not coefficient of discrete fourier transform)
 function can be discontinuous between intervals
 scales domain length to 2pi

 input :
 l,r : end points of piecewise linear function
 lval, rval : values at end points
 L : length of domain
 n : number of samples/highest frequency   

 output :
 a, b : coefficients for frequency components

\end{lstlisting}
\subsection{fourier\_coefficient\_piecewise\_linear\_1}
${}$
\begin{lstlisting}
 fourier series coefficients of a piecewise linear function
 (not coefficient of discrete fourier transform)
 function can be discontinuous between intervals
 scales domain length to 2pi

 input :
 X : end points of piecewise linear function
 Y : values at end points
 
 output :
 ab : coefficients for frequency components

\end{lstlisting}
\subsection{fourier\_coefficient\_ramp3}
${}$
\begin{lstlisting}
 fourier series coefficient of a ramp

\end{lstlisting}
\subsection{fourier\_coefficient\_ramp\_pulse}
${}$
\begin{lstlisting}
 fourier series coefficient of a ramp pules

\end{lstlisting}
\subsection{fourier\_coefficient\_ramp\_step}
${}$
\begin{lstlisting}
 fourier coefficient of a ramp-step

\end{lstlisting}
\subsection{fourier\_coefficient\_square\_pulse}
${}$
\begin{lstlisting}
 fourier series coefficients of a square pulse

\end{lstlisting}
\subsection{fourier\_complete\_negative\_half\_plane}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_cubic\_interaction\_coefficients}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_derivative}
${}$
\begin{lstlisting}
 derivative via fourier transform
 exponential convergence for periodic functions
 results in spurious oscillations for aperiodic functions

 input:
 x : data, sampled in equal intervals 
 k : order of the derivative

 dx : kth-derivative of x

 note : 1) the derivative converges with spectral accuracy, i.e. is
           exact up to rounding condition for L sufficiently large
	     and x being periodic
	  2) the derivative converges with order p, when x has only
	     p-continous derivatives, including discontinuous derivatives
	     over the boundary
	  3) discontinuous derivatives result in gibbs phenomenon

\end{lstlisting}
\subsection{fourier\_derivative\_matrix\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_derivative\_matrix\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_expand}
${}$
\begin{lstlisting}
 expand values of fourier series

\end{lstlisting}
\subsection{fourier\_fit}
${}$
\begin{lstlisting}
 fit a fourier series to a set of sample points that are not spaced in
 equal intervals

\end{lstlisting}
\subsection{fourier\_freq2ind}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_interpolate}
${}$
\begin{lstlisting}
 interpolate samples y sampled at moments (location) t to locations ti

\end{lstlisting}
\subsection{fourier\_matrix}
${}$
\begin{lstlisting}
 transformation matrix for a continuous fourier series
 (not for the discrete dft/fft)

\end{lstlisting}
\subsection{fourier\_matrix2}
${}$
\begin{lstlisting}
 transformation matrix for a continuous fourier series
 (not for the discrete dft/fft)

\end{lstlisting}
\subsection{fourier\_matrix3}
${}$
\begin{lstlisting}
 transformation matrix for the continous fourier transform
 this is a matrix with (2*n+1) real columns

\end{lstlisting}
\subsection{fourier\_matrix\_exp}
${}$
\begin{lstlisting}
 transformation matrix for a continuous fourier series
 (not for the discrete dft/fft)

\end{lstlisting}
\subsection{fourier\_multiplicative\_interaction\_coefficients}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_power}
${}$
\begin{lstlisting}
 powers of a continuous fourier series in sin/cos form

 powers of a^p = (ur + u1 sin(ot) + u2 sin(ot+dp))^p
 phase of first component assumed 0

 frequencies higher than 2-omega ignored in input
 frequencies higher than 3-omega not computed

\end{lstlisting}
\subsection{fourier\_power\_exp}
${}$
\begin{lstlisting}
 powers of the continuous fourier series 
 	a^p = (ur + u1 sin(ot) + u2 sin(ot+dp))^p
 phase of first component assumed 0
 
 higher orders than 2 ignored input
 higher order than 3 not computed in output

 y = a_0 + sum (a_j sin(jot) + b_j cos(jot))
   = Real(sum_{i=0}^inf c_i exp(1i*omega), c_i = a_i + b_i

 NOT the alternative sum_{i=-inf}^inf \tilde c_i, tile c_j = 1/2 a_j + 1/2i b_j

\end{lstlisting}
\subsection{fourier\_predict}
${}$
\begin{lstlisting}
 expand a continous fourier series at times t

\end{lstlisting}
\subsection{fourier\_quadratic\_interaction\_coefficients}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_random\_phase\_walk}
${}$
\begin{lstlisting}
 evaluete fourier series where the phase undergoes a brownian motion

\end{lstlisting}
\subsection{fourier\_range}
${}$
\begin{lstlisting}
 approximate range of a continous Fourier series with 2 components
 range(y) = max(y) - min(y)

\end{lstlisting}
\subsection{fourier\_regress}
${}$
\begin{lstlisting}
 fit a continous fourier series to a set of sample points not sampled
 at equal intervals

\end{lstlisting}
\subsection{fourier\_resampled\_fit}
${}$
\begin{lstlisting}
 fits coefficients of a continuous fourier transform,
 but stores them as resampled values

\end{lstlisting}
\subsection{fourier\_resampled\_predict}
${}$
\begin{lstlisting}
 interpolates a continuous fourier series that has been stored as values
 at their support points

\end{lstlisting}
\subsection{fourier\_signed\_square}
${}$
\begin{lstlisting}
 coefficients of the fourier series of | cos a + cos t | (cos a + cos t)
 in general
            cos a is midrange
            cos t is tidal variation
 c.f Dronkers

\end{lstlisting}
\subsection{fourier\_transform}
${}$
\begin{lstlisting}
 continuous fourier transformation of y
 (not discrete fourier transformation dft/fft)

 input:
	b : data sampled at equal intervals
	T : length of data in time or space, i.e. position of last sample if
	    position of first sample is 0
       T_max : maximum period to include
 
 output :
	A  : fourier matrix
       p  : fourier transformation of b
	tt : TODO 

\end{lstlisting}
\subsection{fourier\_transform\_fractional}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fourier\_truncate\_negative\_half\_plane}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hyperbolic\_fourier\_box}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{idftmtx\_man}
${}$
\begin{lstlisting}
 inverse matrix for the discrete fourier transform in matlab style
 with a limited number of columns, thus ignoring higher frequencies
 keep 2nc+1 columns (mean and conj-complex pairs of nc frequencies)

\end{lstlisting}
\subsection{laplace\_2d\_pwlinear}
${}$
\begin{lstlisting}
 solution to the Laplacian in two dimensions for a finite rectangular domain
 with piecewise constant boundary conditions
 linear system with 4 unknowns per freqency component
 these are coefficients of s,c,sh,ch
	(pu*(s + c) + qu*(s' + c'))*(shu + chu) = ru		% upper bc
	(pd*(s + c) + qd*(s' + c'))*(shd + chd) = rd		% lower bc
	( (sl + cl)*( pl*(shl + chl) + ql*(shl' + chl')) = rl	% left bc
	( (sr + cr)*( pr*(shr + chr) + qr*(shr' + chr')) = rr	% right bc

  least squares with piecewise integration
 [x0,p,q,r] piecewise linear polynomials at the boundaries

\end{lstlisting}
\subsection{mean\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{moments\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{nanfft}
${}$
\begin{lstlisting}
 discrete fourier transform of a data series with gaps

\end{lstlisting}
\subsection{peaks}
${}$
\begin{lstlisting}
 peaks of the power spectrum of a disctrete fourier transform

 rule for peaks: there is no higher value left or right of the "peak"
                 until the signal drops to p*y_peak, p = 0.5

 works best, when spectrum has been smoothened

 input :
 f : frequency
 y : absolute value of fourier transform (power spectrum)
 L : length in space or time of series

 output :

 a0 : amplitude
 s0 : standard deviation (error?) of amplitude
 w0 : width of peak
 lambda = wave length (period?)
 pdx : index of peak
 f : frequency (if not given as input) 

\end{lstlisting}
\subsection{roots\_fourier}
${}$
\begin{lstlisting}
 zeros of continuous fourier series series

	f  = a_0 + sum_j=^n a_i cos(j x) + b_i sin(j x)

\end{lstlisting}
\subsection{spectral\_density}
${}$
\begin{lstlisting}
 spectral density

\end{lstlisting}
\subsection{std\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_complex\_exp\_product}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier\_filter}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_idftmtx}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{var\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{gaussfit\_quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{geometry/@Geometry}
\subsection{Geometry}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{arclength}
${}$
\begin{lstlisting}
 arc length of a two dimensional curve

 8th order accurate
 does not require the segments length to vary smoothly

 note: the curve can be considered parametric, e.g. x = x(t), y=y(t) and
 	and t = t(s), but the error term contains derivatives of t,
      thus a non smooth t (strongly varying distance between points)
      requires the scaling as done below

\end{lstlisting}
\subsection{arclength\_old}
${}$
\begin{lstlisting}
 arc length of a two dimensional function

\end{lstlisting}
\subsection{arclength\_old2}
${}$
\begin{lstlisting}
 arc length of a two dimensional function

\end{lstlisting}
\subsection{base\_point}
${}$
\begin{lstlisting}
 base point (fusspunkt), i.e. point on a line with shortest distance
 to another point

\end{lstlisting}
\subsection{base\_point\_limited}
${}$
\begin{lstlisting}
 base point (Fusspunkt) of a point on a line

\end{lstlisting}
\subsection{centroid}
${}$
\begin{lstlisting}
 centroid of a polygone

\end{lstlisting}
\subsection{cosa\_min\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cross2}
${}$
\begin{lstlisting}
 cross product in two dimensions

\end{lstlisting}
\subsection{curvature}
${}$
\begin{lstlisting}
 curvature of a function in two dimensions

\end{lstlisting}
\subsection{ddot}
${}$
\begin{lstlisting}
 sum of squares of cos of inner angles of triangle

\end{lstlisting}
\subsection{distance}
${}$
\begin{lstlisting}
 equclidan distance between two points

\end{lstlisting}
\subsection{distance2}
${}$
\begin{lstlisting}
 euclidean distance between two points
 this function requires a and be of equal dimensions, or the least the first pair or second pair to be a scalar

\end{lstlisting}
\subsection{dot}
${}$
\begin{lstlisting}
 dot product

\end{lstlisting}
\subsection{edge\_length}
${}$
\begin{lstlisting}
 edge length

\end{lstlisting}
\subsection{enclosed\_angle}
${}$
\begin{lstlisting}
 angle enclosed between two lines

\end{lstlisting}
\subsection{enclosing\_triangle}
${}$
\begin{lstlisting}
 smallest enclosing equilateral triangle with bottom site paralle to X axis

\end{lstlisting}
\subsection{hexagon}
${}$
\begin{lstlisting}
 coordinates of a hexagon, scaled and rotated

\end{lstlisting}
\subsection{inPolygon}
${}$
\begin{lstlisting}
 flag points contained in a polygon
 much faster than matlab internal function

\end{lstlisting}
\subsection{inTetra}
${}$
\begin{lstlisting}
 flag points contained in tetrahedron

\end{lstlisting}
\subsection{inTetra2}
${}$
\begin{lstlisting}
 flag points contained in tetrahedron

\end{lstlisting}
\subsection{inTriangle}
${}$
\begin{lstlisting}
 flag points contained in triangle
 function [flag, c] = inTriangle(P1,P2,P3,P0)

\end{lstlisting}
\subsection{intersect}
${}$
\begin{lstlisting}
 intersect between two lines

\end{lstlisting}
\subsection{lineintersect}
${}$
\begin{lstlisting}
 intersect of two lines

\end{lstlisting}
\subsection{lineintersect1}
${}$
\begin{lstlisting}
 intersect of two lines

\end{lstlisting}
\subsection{minimum\_distance\_lines}
${}$
\begin{lstlisting}
 minimum distance of two lines in three dimensions

\end{lstlisting}
\subsection{mittenpunkt}
${}$
\begin{lstlisting}
 mittenpunkt of a triangle

\end{lstlisting}
\subsection{nagelpoint}
${}$
\begin{lstlisting}
 nagelpoint of a triangle

\end{lstlisting}
\subsection{onLine}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{orthocentre}
${}$
\begin{lstlisting}
 orthocentre of triangle

\end{lstlisting}
\subsection{plumb\_line}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{poly\_area}
${}$
\begin{lstlisting}
 area of a polygon
 function A = poly_area(x,y)

\end{lstlisting}
\subsection{poly\_edges}
${}$
\begin{lstlisting}
 edges of a polygon

\end{lstlisting}
\subsection{poly\_set}
${}$
\begin{lstlisting}
 associate point at arbitary location with a polygon it is contained in
 and assign the value of the polygon to it

\end{lstlisting}
\subsection{poly\_width}
${}$
\begin{lstlisting}
 width of polygon width holes by surface normals
 holes / islands separated with NaN
 order of points of outer boundary must be cw
 order of points of holes must be ccw
 note that this function does not give the true width for expanding sections
 use voronoi polygons for this

\end{lstlisting}
\subsection{polyxpoly}
${}$
\begin{lstlisting}
 intersections of two polygons

\end{lstlisting}
\subsection{project\_to\_curve}
${}$
\begin{lstlisting}
 closest point on a curve with respect to a point at distance to the curve

\end{lstlisting}
\subsection{quad\_isconvex}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{random\_disk}
${}$
\begin{lstlisting}
 draw random points on the unit disk

\end{lstlisting}
\subsection{random\_simplex}
${}$
\begin{lstlisting}
 random point inside of a triangle

\end{lstlisting}
\subsection{sphere\_volume}
${}$
\begin{lstlisting}
 volume of a sphere
 function v = sphere_volume(r)

\end{lstlisting}
\subsection{tetra\_volume}
${}$
\begin{lstlisting}
 volume of a tetrahedron

\end{lstlisting}
\subsection{tobarycentric}
${}$
\begin{lstlisting}
 cartesian to barycentric coordinates

\end{lstlisting}
\subsection{tobarycentric1}
${}$
\begin{lstlisting}
 cartesian to barycentric coordinates

\end{lstlisting}
\subsection{tobarycentric2}
${}$
\begin{lstlisting}
 cartesian to barycentric coordinates

\end{lstlisting}
\subsection{tobarycentric3}
${}$
\begin{lstlisting}
 cartesian to barycentric coordinates

\end{lstlisting}
\subsection{tri\_angle}
${}$
\begin{lstlisting}
 cos of angles of a triangle

\end{lstlisting}
\subsection{tri\_area}
${}$
\begin{lstlisting}
 angle of a triangle

\end{lstlisting}
\subsection{tri\_centroid}
${}$
\begin{lstlisting}
 centroid of a triangle

\end{lstlisting}
\subsection{tri\_distance\_opposit\_midpoint}
${}$
\begin{lstlisting}
 distance between corner of a triangle and its opposing mid-point

\end{lstlisting}
\subsection{tri\_edge\_length}
${}$
\begin{lstlisting}
 edge length of a triangle

\end{lstlisting}
\subsection{tri\_edge\_midpoint}
${}$
\begin{lstlisting}
 mid point of a triangle

\end{lstlisting}
\subsection{tri\_excircle}
${}$
\begin{lstlisting}
 excircle of a triangle

\end{lstlisting}
\subsection{tri\_height}
${}$
\begin{lstlisting}
 height of a triangle

\end{lstlisting}
\subsection{tri\_incircle}
${}$
\begin{lstlisting}
 incircle of a triangle

\end{lstlisting}
\subsection{tri\_isacute}
${}$
\begin{lstlisting}
 flag acute triangles

\end{lstlisting}
\subsection{tri\_isobtuse}
${}$
\begin{lstlisting}
 flag obntuse triangles

\end{lstlisting}
\subsection{tri\_semiperimeter}
${}$
\begin{lstlisting}
 semiperimeter of a triangle

\end{lstlisting}
\subsection{tri\_side\_length}
${}$
\begin{lstlisting}
 edge lenght of triangle

\end{lstlisting}
\section{geometry}
\subsection{Polygon}
${}$
\begin{lstlisting}
 Simple 2D polygon class

   Polygon properties:
       x - x coordinates of polygon
       y - y coordinates of polygon
       nnodes - number of nodes in the polygon

   Polygon methods:
       in - checks whether given points lie inside, on the edge, or outside of the polygon
       area - returns the area of the polygon
       centerline - computes the centerline of the river
       iscw - check whether polygon is clockwise
       reverse - reverse the order of the polygon

\end{lstlisting}
\subsection{bounding\_box}
${}$
\begin{lstlisting}
 bounding box of X

\end{lstlisting}
\subsection{curvature\_1d}
${}$
\begin{lstlisting}
 curvature of a sampled parametric curve in two dimensions

\end{lstlisting}
\subsection{cvt}
${}$
\begin{lstlisting}
 centroidal voronoi tesselation

\end{lstlisting}
\subsection{deg\_to\_frac}
${}$
\begin{lstlisting}
 degree, minutes and seconds to fractions

\end{lstlisting}
\subsection{ellipse}
${}$
\begin{lstlisting}
 return points on an ellipse
 n : number of points
 ci : confidence interval, i.e. for 1 sigma

\end{lstlisting}
\subsection{ellipseX}
${}$
\begin{lstlisting}
 x-coordinates of y-coordinates of an ellipse

\end{lstlisting}
\subsection{ellipseY}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{first\_intersect}
${}$
\begin{lstlisting}
 get first intersection between lines in A and B

\end{lstlisting}
\subsection{golden\_ratio}
${}$
\begin{lstlisting}
 golden ratio

\end{lstlisting}
\subsection{hypot3}
${}$
\begin{lstlisting}
 hypothenuse in 3D

\end{lstlisting}
\subsection{meanangle}
${}$
\begin{lstlisting}
 weighted mean of angles

\end{lstlisting}
\subsection{meanangle2}
${}$
\begin{lstlisting}
 mean angle

\end{lstlisting}
\subsection{meanangle3}
${}$
\begin{lstlisting}
 mean angle

\end{lstlisting}
\subsection{meanangle4}
${}$
\begin{lstlisting}
 mean angle

\end{lstlisting}
\subsection{medianangle}
${}$
\begin{lstlisting}
 median angle
 angle, that has the smallest squared distance to all others

\end{lstlisting}
\subsection{medianangle2}
${}$
\begin{lstlisting}
 median angle

 input
 alpha : x*m, [rad] angle

 ouput
 ma    : 1*m, [rad] median angle
 sa    : 1*m, [rad] standard error of median angle for uncorrelated error

\end{lstlisting}
\subsection{pilim}
${}$
\begin{lstlisting}
 limit to +- pi

\end{lstlisting}
\subsection{streamline\_radius\_of\_curvature}
${}$
\begin{lstlisting}
 streamline radius of curvature
 simplifies when rotatate to streamwise coordinates to R = 1/dv/ds * u

\end{lstlisting}
\section{histogram/@Histogram}
\subsection{2x}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{Histogram}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bimodes}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cdfS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{chi2test}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cmoment}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cmomentS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{entropy}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{entropyS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{export\_csv}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{iquantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kstest}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kurtosis}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kurtosisS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{meanS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{median}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{medianS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{modeS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{moment}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{momentS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantileS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{resample}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{setup}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewness}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewnessS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{stairs}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{stairsS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{stdS}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{var}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{varS}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{histogram}
\subsection{hist\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{histadapt}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{histconst}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pdf\_poly}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plotcdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_histogram}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{imrotmat}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra}
\subsection{averaging\_matrix\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{colnorm}
${}$
\begin{lstlisting}
 norms of columns

\end{lstlisting}
\subsection{condest\_}
${}$
\begin{lstlisting}
 estimation of the condition number

\end{lstlisting}
\subsection{connectivity\_matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra/coordinate-transformation}
\subsection{barycentric2cartesian}
${}$
\begin{lstlisting}
 barycentric to cartesian coordinates

\end{lstlisting}
\subsection{barycentric2cartesian3}
${}$
\begin{lstlisting}
 convert barycentric to cartesian coordinates

\end{lstlisting}
\subsection{cartesian2barycentric}
${}$
\begin{lstlisting}
 cartesian to barycentric coordinates

\end{lstlisting}
\subsection{cartesian\_to\_unit\_triangle\_basis}
${}$
\begin{lstlisting}
 transform coodinates into unit triangle

\end{lstlisting}
\subsection{ellipsoid2geoid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{example\_approximate\_utm\_conversion}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{latlon2utm}
${}$
\begin{lstlisting}
 transform latitude and longitude to WGS84 UTM

\end{lstlisting}
\subsection{latlon2utm\_simple}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowrance\_mercator\_to\_wgs84}
${}$
\begin{lstlisting}
 convert lowrance coordinates to wgs84

 based on spreadsheet by D Whitney King and Patty B at Lowrance

\end{lstlisting}
\subsection{nmea2utm}
${}$
\begin{lstlisting}
 convert nmea messages to utm coordinates

\end{lstlisting}
\subsection{sn2xy}
${}$
\begin{lstlisting}
 convert sn to xy coordinates

\end{lstlisting}
\subsection{unit\_triangle\_to\_cartesian}
${}$
\begin{lstlisting}
 transform coordinates in unit triangle to cartesian coordinates

\end{lstlisting}
\subsection{utm2latlon}
${}$
\begin{lstlisting}
 convert wgs84 utm to latitute and longitude

\end{lstlisting}
\subsection{xy2nt}
${}$
\begin{lstlisting}
 project all points onto the cross section and assign them nz-coordinates

 transform coordinate into N-T reference
 rotate coordinate, so that cross section goes along x-axis
 then x and y are n and t respectively scaled by width
 N and T coordinates

\end{lstlisting}
\subsection{xy2sn}
${}$
\begin{lstlisting}
 convert cartesian to streamwise coordiantes

\end{lstlisting}
\subsection{xy2sn\_java}
${}$
\begin{lstlisting}
 use java port for speed up

\end{lstlisting}
\subsection{xy2sn\_old}
${}$
\begin{lstlisting}
 transform points from cartesian into streamwise coordinates

 NOTE : prefer the java version, this has some problems with round off

\end{lstlisting}
\section{linear-algebra}
\subsection{det2x2}
${}$
\begin{lstlisting}
 2x2 matrix inverse of 2x2 matrices stacked along dim 3

\end{lstlisting}
\subsection{det3x3}
${}$
\begin{lstlisting}
 determinant of stacked 3x3 matrices

\end{lstlisting}
\subsection{det4x4}
${}$
\begin{lstlisting}
 determinant of stacked 4x4 matrices

\end{lstlisting}
\subsection{diag2x2}
${}$
\begin{lstlisting}
 diagonal of stacked 2x2 matrices

\end{lstlisting}
\subsection{down}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{eig2x2}
${}$
\begin{lstlisting}
 eigenvalues of stacked 2x2 matrices

\end{lstlisting}
\section{linear-algebra/eigenvalue}
\subsection{eig\_bisection}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{eig\_inverse}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{eig\_inverse\_iteration}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{eig\_power\_iteration}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra/eigenvalue/jacobi-davidson}
\subsection{afun\_jdm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{davidson}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jacobi\_davidson}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jacobi\_davidson\_qr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jacobi\_davidson\_qz}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jacobi\_davidson\_simple}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jdqr}
${}$
\begin{lstlisting}
% Read/set parameters
% Initiate global variables
% Return if eigenvalueproblem is trivial
% Initialize V, W:
%   V,W orthonormal, A*V=W*R+Qschur*E, R upper triangular
% The JD loop (Standard)
%    V orthogonal, V orthogonal to Qschur
%    V*V=eye(j), Qschur'*V=0, 
%    W=A*V, M=V'*W
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1; 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    Both V and W orthonormal and orthogonal w.r.t. Qschur
%    V*V=eye(j), Qschur'*V=0, W'*W=eye(j), Qschur'*W=0
%    (A*V-tau*V)=W*R+Qschur*E, E=Qschur'*(A*V-tau*V), M=W'*V
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    V W AV.
%    Both V and W orthonormal and orthogonal w.r.t. Qschur, AV=A*V-tau*V
%    V*V=eye(j),  W'*W=eye(j), Qschur'*V=0, Qschur'*W=0, 
%    (I-Qschur*Qschur')*AV=W*R, M=W'*V; R=W'*AV;
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    W orthonormal, V and W orthogonal to Qschur, 
%    W'*W=eye(j), Qschur'*V=0, Qschur'*W=0
%    W=(A*V-tau*V)-Qschur*E, E=Qschur'*(A*V-tau*V), 
%    M=W'*V
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
 W=V*Q; V=V(:,1:j)/R; E=E/R; R=eye(j); M=Q(1:j,:)'/R;
 W=V*H; V(:,j+1)=[];R=R'*R;   M=H(1:j,:)';
%======== ARNOLDI (for initializing spaces) ===============================
%=========== END ARNOLDI ============================================  
% not accurate enough M=Rw'\(M/Rv);
%=========== COMPUTE SORTED JORDAN FORM ==================================
% compute vectors and matrices for skew projection
% solve preconditioned system
% 0 step of bicgstab eq. 1 step of bicgstab
% Then x is a multiple of b
% HIST=[0,1]; 
 explicit preconditioning
% compute norm in l-space
%  HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
 implicit preconditioning
% collect the updates for x in l-space
% but, do the orth to Q implicitly
% compute norm in l-space
% HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
% Do the orth to Q explicitly
% In exact arithmetic not needed, but
% appears to be more stable.
%  plot(HIST(:,1),log10(HIST(:,2)+eps),'*'), drawnow, pause
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
%======================================================================
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
 HIST=1; 
% Lucky break-down
 HIST=[HIST;(gamma~=0)/sqrt(rho)]; 
% Lucky break-down
% solve in least square sense 
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow,% pause
 r=r/rho; rho=1; 
%  HIST=rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow,% pause
% HIST = rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow, pause
% HIST = rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow, pause
%------ compute schur form -------------
 A*Q=Q*S, Q'*Q=eye(size(A));
% transform real schur form to complex schur form
%------ find order eigenvalues ---------------
%------ reorder schur form ----------------
%------ compute qz form ----------------
%------ sort eigenvalues ---------------
%------ sort qz form -------------------
% i>j, move ith eigenvalue to position j 
% determine dimension
% defaults
%% 'v'

\end{lstlisting}
\subsection{jdqr\_sleijpen}
${}$
\begin{lstlisting}
% Read/set parameters
% Initiate global variables
% Return if eigenvalueproblem is trivial
% Initialize V, W:
%   V,W orthonormal, A*V=W*R+Qschur*E, R upper triangular
% The JD loop (Standard)
%    V orthogonal, V orthogonal to Qschur
%    V*V=eye(j), Qschur'*V=0, 
%    W=A*V, M=V'*W
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1; 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    Both V and W orthonormal and orthogonal w.r.t. Qschur
%    V*V=eye(j), Qschur'*V=0, W'*W=eye(j), Qschur'*W=0
%    (A*V-tau*V)=W*R+Qschur*E, E=Qschur'*(A*V-tau*V), M=W'*V
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    V W AV.
%    Both V and W orthonormal and orthogonal w.r.t. Qschur, AV=A*V-tau*V
%    V*V=eye(j),  W'*W=eye(j), Qschur'*V=0, Qschur'*W=0, 
%    (I-Qschur*Qschur')*AV=W*R, M=W'*V; R=W'*AV;
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    W orthonormal, V and W orthogonal to Qschur, 
%    W'*W=eye(j), Qschur'*V=0, Qschur'*W=0
%    W=(A*V-tau*V)-Qschur*E, E=Qschur'*(A*V-tau*V), 
%    M=W'*V
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
 W=V*Q; V=V(:,1:j)/R; E=E/R; R=eye(j); M=Q(1:j,:)'/R;
 W=V*H; V(:,j+1)=[];R=R'*R;   M=H(1:j,:)';
%======== ARNOLDI (for initializing spaces) ===============================
%=========== END ARNOLDI ============================================  
% not accurate enough M=Rw'\(M/Rv);
%=========== COMPUTE SORTED JORDAN FORM ==================================
% compute vectors and matrices for skew projection
% solve preconditioned system
% 0 step of bicgstab eq. 1 step of bicgstab
% Then x is a multiple of b
% HIST=[0,1]; 
 explicit preconditioning
% compute norm in l-space
%  HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
 implicit preconditioning
% collect the updates for x in l-space
% but, do the orth to Q implicitly
% compute norm in l-space
% HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
% Do the orth to Q explicitly
% In exact arithmetic not needed, but
% appears to be more stable.
%  plot(HIST(:,1),log10(HIST(:,2)+eps),'*'), drawnow, pause
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
%======================================================================
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
 HIST=1; 
% Lucky break-down
 HIST=[HIST;(gamma~=0)/sqrt(rho)]; 
% Lucky break-down
% solve in least square sense 
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow,% pause
 r=r/rho; rho=1; 
%  HIST=rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow,% pause
% HIST = rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow, pause
% HIST = rho;
%  HIST=[HIST;rho];
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow, pause
%------ compute schur form -------------
 A*Q=Q*S, Q'*Q=eye(size(A));
% transform real schur form to complex schur form
%------ find order eigenvalues ---------------
%------ reorder schur form ----------------
%------ compute qz form ----------------
%------ sort eigenvalues ---------------
%------ sort qz form -------------------
% i>j, move ith eigenvalue to position j 
% determine dimension
% defaults
%% 'v'

\end{lstlisting}
\subsection{jdqr\_vorst}
${}$
\begin{lstlisting}
% Read/set parameters
% Initiate global variables
% Return if eigenvalueproblem is trivial
% Initialize V, W:
%   V,W orthonormal, A*V=W*R+Qschur*E, R upper triangular
% The JD loop (Standard)
%    V orthogonal, V orthogonal to Qschur
%    V*V=eye(j), Qschur'*V=0, 
%    W=A*V, M=V'*W
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1; 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    Both V and W orthonormal and orthogonal w.r.t. Qschur
%    V*V=eye(j), Qschur'*V=0, W'*W=eye(j), Qschur'*W=0
%    (A*V-tau*V)=W*R+Qschur*E, E=Qschur'*(A*V-tau*V), M=W'*V
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    V W AV.
%    Both V and W orthonormal and orthogonal w.r.t. Qschur, AV=A*V-tau*V
%    V*V=eye(j),  W'*W=eye(j), Qschur'*V=0, Qschur'*W=0, 
%    (I-Qschur*Qschur')*AV=W*R, M=W'*V; R=W'*AV;
%
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
% The JD loop (Harmonic Ritz values)
%    W orthonormal, V and W orthogonal to Qschur, 
%    W'*W=eye(j), Qschur'*V=0, Qschur'*W=0
%    W=(A*V-tau*V)-Qschur*E, E=Qschur'*(A*V-tau*V), 
%    M=W'*V
% Compute approximate eigenpair and residual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Check for convergence
% Expand the partial Schur form
 Rschur=[[Rschur;zeros(1,k)],Qschur'*MV(u)]; k=k+1;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Expand preconditioned Schur matrix PinvQ
% Check for shrinking the search subspace
% Solve correction equation
% Expand the subspaces of the interaction matrix  
 W=V*Q; V=V(:,1:j)/R; E=E/R; R=eye(j); M=Q(1:j,:)'/R;
 W=V*H; V(:,j+1)=[];R=R'*R;   M=H(1:j,:)';
%======== ARNOLDI (for initializing spaces) ===============================
%=========== END ARNOLDI ============================================  
% not accurate enough M=Rw'\(M/Rv);
%=========== COMPUTE SORTED JORDAN FORM ==================================
% accepted separation between eigenvalues:
% no preconditioning
% solve left preconditioned system
% compute vectors and matrices for skew projection
% precondion and project r
% solve preconditioned system
% no preconditioning
% solve two-sided expl. precond. system
% compute vectors and matrices for skew projection
% precondion and project r
% solve preconditioned system
% "unprecondition" solution
%%%% u(:,j+1)=Atilde*u(:,j)
%%%% r(:,j+1)=Atilde*r(:,j)
%------ compute schur form -------------
 A*Q=Q*S, Q'*Q=eye(size(A));
% transform real schur form to complex schur form
%------ find order eigenvalues ---------------
%------ reorder schur form ----------------
%------ compute qz form ----------------
%------ sort eigenvalues ---------------
%------ sort qz form -------------------
% i>j, move ith eigenvalue to position j 
% determine dimension
% defaults

\end{lstlisting}
\subsection{jdqz}
${}$
\begin{lstlisting}
% Read/set parameters
% Return if eigenvalueproblem is trivial
% Initialize target, test space and interaction matrices
% V=RepGS(Qschur,V); [AV,BV]=MV(V); %%% more stability??
% W=RepGS(Zschur,eval(testspace));  %%% dangerous if sigma~lambda
% Solve the preconditioned correction equation
% Expand the subspaces and the interaction matrices
% Check for stagnation
% Solve projected eigenproblem
% Compute approximate eigenpair and residual
%=== an alternative, but less stable way of computing z =====
% display history
% save history
% check convergence 
% EXPAND Schur form
% Expand preconditioned Schur matrix MinvZ=M\Zschur
% check for conjugate pair
% To detect whether another eigenpair is accurate enough 
% restart if dim(V)> jmax
% Initialize target, test space and interaction matrices
% additional stabilisation. May not be needed
% V=RepGS(Zschur,V); [AV,BV]=MV(V); 
% end add. stab.
% Solve the preconditioned correction equation
% expand the subspaces and the interaction matrices
% Check for stagnation
% compute approximate eigenpair
% Compute approximate eigenpair and residual
% display history
% save history
% check convergence 
% expand Schur form
% ZastQ=Z'*Q0  
% the final Qschur
% check for conjugate pair
% t perp Zschur, t in span(Q0,imag(q)) 
% To detect whether another eigenpair is accurate enough
% restart if dim(V)> jmax
%======== END JDQZ ====================================================
%======================================================================
%======== PREPROCESSING ===============================================
%======================================================================
%======== ARNOLDI (for initial spaces) ================================        
%% then precond=I and target = 0: apply Arnoldi with A
%======== END ARNOLDI =================================================
%======================================================================
%======== POSTPROCESSING ==============================================
%======================================================================
%======== SORT QZ DECOMPOSITION INTERACTION MATRICES ==================
%======== COMPUTE SORTED JORDAN FORM ==================================
%======== END JORDAN FORM =============================================
%======== OUTPUT ======================================================
%======================================================================
%======== UPDATE PRECONDITIONED SCHUR VECTORS =========================
%======================================================================
%======================================================================
%======== SOLVE CORRECTION EQUATION ===================================
%======================================================================
% solve preconditioned system
%======================================================================
%======== LINEAR SOLVERS ==============================================
%======================================================================
% [At,Bt]=MV(x); At=theta(2)*At-theta(1)*Bt; 
% xtol=norm(r-At+Z*(Z'*At))/norm(r); 
%===== Iterative methods ==============================================
% 0 step of bicgstab eq. 1 step of bicgstab
% Then x is a multiple of b
% HIST=[0,1];
 explicit preconditioning
% compute norm in l-space
% HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
 implicit preconditioning
% collect the updates for x in l-space
% but, do the orth to Z implicitly
% compute norm in l-space
% HIST=[HIST;[nmv,rnrm/snrm]];
% sufficient accuracy. No need to update r,u
% Do the orth to Z explicitly
% In exact arithmetic not needed, but
% appears to be more stable.
% plot(HIST(:,1),log10(HIST(:,2)+eps),'*'), drawnow
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
%======================================================================
% 0 step of gmres eq. 1 step of gmres
% Then x is a multiple of b
 HIST=1;
% Lucky break-down
 HIST=[HIST;(gamma~=0)/sqrt(rho)]; 
% Lucky break-down
% solve in least square sense 
 HIST=log10(HIST+eps); J=[0:size(HIST,1)-1]';
 plot(J,HIST(:,1),'*'); drawnow
%======== END SOLVE CORRECTION EQUATION ===============================       
%======================================================================
%======== BASIC OPERATIONS ============================================
%======================================================================
 y(1:5,1), pause
%======== COMPUTE r AND z =============================================
% E*u=Q*sigma, sigma(1,1)>sigma(2,2)
%======== END computation r and z =====================================
%======================================================================
%======== Orthogonalisation ===========================================
%======================================================================
%======== END  Orthogonalisation ======================================
%======================================================================
%======== Sorts Schur form ============================================
%======================================================================
    kappa=max(norm(A,inf)/max(norm(B,inf),1.e-12),1);
    kappa=2^(round(log2(kappa)));
%------ compute the qz factorization -------
%------ scale the eigenvalues --------------
%------ sort the eigenvalues ---------------
%------ swap the qz form -------------------
% repeat SwapQZ if angle is too small
%======================================================================
%======================================================================
% i>j, move ith eigenvalue to position j 
% compute q s.t. C*q=(t(i,1)*S-s(i,1)*T)*q=0
 C*P=Q*R
 check whether last but one diag. elt r nonzero
 C*q
% end computation q
%======== END sort QZ decomposition interaction matrices ==============
%======================================================================
%======== INITIALIZATION ==============================================
%======================================================================
%======================================================================
% defaults              %%%% search for 'xx' in fieldnames
%% 'ma'
%% 'sch'
%% 'to'
%% 'di'
% jmin=nselect+p0 %%%% 'jmi'
% jmax=jmin+p1    %%%% 'jma'
%% 'te'
%% 'pai'
%% 'av'
%% 'tr'
%% 'fix'
%% 'ns'
%% 'ch'
%% 'lso'
%% 'ls_m'
%% 'ls_t' 
%% 'ls_e'
%% 'ty'
%% 'l_'
%% 'u_'
%% 'p_'
%% 'sca'
%% 'v0'
 initiation
 'standard'
 'harmonic'
 'searchspace'
%======================================================================
% or Operator_Form=3 or Operator_Form=5???
%======================================================================
%========= DISPLAY FUNCTIONS ===========================================
%======================================================================
%======================================================================
%======================================================================
%======================================================================

\end{lstlisting}
\subsection{mfunc\_jdm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mgs}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{minres\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mv\_jacobi\_davidson}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra}
\subsection{first}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gershgorin\_circle}
${}$
\begin{lstlisting}
 range of eigenvalues determined by the gershgorin circle theorem

\end{lstlisting}
\subsection{haussdorff}
${}$
\begin{lstlisting}
 haussdorf dimension
 box counting: count cectangles passed through by line (covered by polygon)

 Koch snow flake 3:4 -> 1.2619
 Kantor set      2:3, (4:9) ->  0.6309
 quadrat         4:2, 9:3, 16:4 -> 2


\end{lstlisting}
\subsection{ieig2x2}
${}$
\begin{lstlisting}
 reconstruct matrix from eigenvalue decomposition

\end{lstlisting}
\subsection{inv2x2}
${}$
\begin{lstlisting}
 2x2 inverse of stacked matrices

\end{lstlisting}
\subsection{inv3x3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{inv4x4}
${}$
\begin{lstlisting}
 inverse of stacked 4x4 matrices

\end{lstlisting}
\subsection{kernel2matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra/lanczos}
\subsection{arnoldi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{arnoldi\_new}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{eigs\_lanczos\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lanczos}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lanczos\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lanczos\_biorthogonal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lanczos\_biorthogonal\_improved}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lanczos\_ghep}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mv\_lanczos}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{reorthogonalise}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lanczos}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra}
\subsection{laplacian\_eigenvalue}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{laplacian\_eigenvector}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{laplacian\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{least\_squares\_perpendicular\_offset}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{left}
${}$
\begin{lstlisting}
 left element of vector, leftmost column is extrapolated

\end{lstlisting}
\section{linear-algebra/linear-systems}
\subsection{gmres\_man}
${}$
\begin{lstlisting}
 break on convergence

\end{lstlisting}
\subsection{minres\_recycle}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{linear-algebra}
\subsection{lpmean}
${}$
\begin{lstlisting}
 mean of pth-power of a

\end{lstlisting}
\subsection{lpnorm}
${}$
\begin{lstlisting}
 norm of lth-power of a

\end{lstlisting}
\subsection{matvec3}
${}$
\begin{lstlisting}
 matrix-vector product of stacked matrices and vectors

\end{lstlisting}
\subsection{max2d}
${}$
\begin{lstlisting}
 maximum value and i-j index for matrix

\end{lstlisting}
\subsection{mid}
${}$
\begin{lstlisting}
 mid point between neighbouring vector elements

\end{lstlisting}
\subsection{mpoweri}
${}$
\begin{lstlisting}
 approximation of A^p, where p is not integer by quadtratic interpolation

\end{lstlisting}
\subsection{mtimes2x2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mtimes3x3}
${}$
\begin{lstlisting}
 product of stacked 3x3 matrices

\end{lstlisting}
\subsection{nannorm}
${}$
\begin{lstlisting}
 norm of a vector, skips nan-values

\end{lstlisting}
\subsection{nanshift}
${}$
\begin{lstlisting}
 shift vector, but set out of range values to NaN

\end{lstlisting}
\subsection{nl}
${}$
\begin{lstlisting}
 number rows (lines) of a matrix

 analogue to unix nl command

\end{lstlisting}
\subsection{normalise}
${}$
\begin{lstlisting}
 normalise a vector or the columns of a matrix
 note that the columns are independently normalised, and hence not necessarily
 orthogonal to each other use the gram schmidt algorithm for this (qr or orth)

\end{lstlisting}
\subsection{normalize1}
${}$
\begin{lstlisting}
 normalize columns in x to [-1,1]

\end{lstlisting}
\subsection{normrows}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{orth2}
${}$
\begin{lstlisting}
 make matrix A orhogonal to B

\end{lstlisting}
\subsection{orth\_man}
${}$
\begin{lstlisting}
 orthogonalize the columns of A

\end{lstlisting}
\subsection{orthogonalise}
${}$
\begin{lstlisting}
 make x orthogonal to Y

\end{lstlisting}
\subsection{padd2}
${}$
\begin{lstlisting}
 padd values around a 2d (image) matrix, constant exprapolation

\end{lstlisting}
\subsection{paddext}
${}$
\begin{lstlisting}
 padd values to vactor
 not suitable for noisy data
 order = 0 : constant extrapolation (hold)
 order = 1 : linear extrapolation

\end{lstlisting}
\subsection{paddval1}
${}$
\begin{lstlisting}
 padd values at end of x

\end{lstlisting}
\subsection{paddval2}
${}$
\begin{lstlisting}
 padd values to x

\end{lstlisting}
\section{linear-algebra/polynomial}
\subsection{chebychev}
${}$
\begin{lstlisting}
 chebycheff polynomials

\end{lstlisting}
\subsection{piecewise\_polynomial}
${}$
\begin{lstlisting}
 evaluate piecewise polynomial

\end{lstlisting}
\subsection{roots1}
${}$
\begin{lstlisting}
 roots of linear functions

\end{lstlisting}
\subsection{roots2}
${}$
\begin{lstlisting}
 roots of quadratic function
 c1 x^2 + c2 x + c3 = 0

\end{lstlisting}
\subsection{roots2poly}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{roots3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{roots4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{roots\_piecewise\_linear}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_roots4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vanderi\_1d}
${}$
\begin{lstlisting}
 vandermonde matrix of an integral

\end{lstlisting}
\section{linear-algebra}
\subsection{randrot}
${}$
\begin{lstlisting}
 random rotation matrix

\end{lstlisting}
\subsection{right}
${}$
\begin{lstlisting}
 get right column by shifting columns to left
 extrapolate rightmost column

\end{lstlisting}
\subsection{rot2}
${}$
\begin{lstlisting}
 rotation matrix from angle

\end{lstlisting}
\subsection{rot2dir}
${}$
\begin{lstlisting}
 rotation matrix from direction vector

\end{lstlisting}
\subsection{rot3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{rotR}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{rownorm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{simmilarity\_matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spnorm}
${}$
\begin{lstlisting}
 frobenius norm

\end{lstlisting}
\subsection{spzeros}
${}$
\begin{lstlisting}
 allocate a sparze matrix of zeros

\end{lstlisting}
\subsection{test\_roots3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{transform\_minmax}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{transpose3}
${}$
\begin{lstlisting}
 transpose stacked 3x3 matrices

\end{lstlisting}
\subsection{transposeall}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{up}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vander\_nd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vanderd\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{logic}
\begin{lstlisting}
bitwise operations on integers


\end{lstlisting}
\subsection{bitor\_man}
${}$
\begin{lstlisting}
 bitwise OR of the numbers of the columns of A

 input:
	A (positive integer)

\end{lstlisting}
\section{master/plot}
\subsection{attach\_boundary\_value}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cartesian\_polar}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{img\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_basis\_functions}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_convergence}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_dof}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_eigenbar}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_error\_estimation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_error\_estimation\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_error\_fem}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_fdm\_kernel}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_fdm\_vs\_fem}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_fem\_accuracy}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_function\_and\_grid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_hat}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_hydrogen\_wf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_mesh}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_mesh\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_refine}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_refine\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_runtime}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_spectrum}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{plot\_wavefunction}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{master/ported}
\subsection{assemble\_2d\_phi\_phi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_3d\_dphi\_dphi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_3d\_phi\_phi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{dV\_2d\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derivative\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derivative\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{element\_neighbour\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{prefetch\_2d\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_2d\_3\_10}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_2d\_3\_15}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_2d\_3\_21}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_2d\_3\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_3d\_4\_10}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_3d\_4\_20}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_3d\_4\_35}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vander\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vander\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{monotoneous\_indices}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{nearest\_fractional\_timestep}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{number-theory}
\subsection{ceiln}
${}$
\begin{lstlisting}
 floor to leading n-digits

\end{lstlisting}
\subsection{digitsb}
${}$
\begin{lstlisting}
 number of digits with respect to specified base

\end{lstlisting}
\subsection{floorn}
${}$
\begin{lstlisting}
 floor to n-digits

\end{lstlisting}
\subsection{iseven}
${}$
\begin{lstlisting}
 true for even numbers in X

\end{lstlisting}
\subsection{multichoosek}
${}$
\begin{lstlisting}
 all combinations of lenght k from set values with repetitions
 c.f. nchoosek, combinations without repetition

 input :
 	x : scalar integer or vector of arbitrary numbers
	k : length of subsets
 output :
	if x scalar : number of combinations  
	if x vector : the exact combinations


\end{lstlisting}
\subsection{nchoosek\_man}
${}$
\begin{lstlisting}
 vecotrised binomial coefficient
 b = N!/K!(N-K)!

\end{lstlisting}
\subsection{pythagorean\_triple}
${}$
\begin{lstlisting}
 pythagorean triple

\end{lstlisting}
\subsection{roundn}
${}$
\begin{lstlisting}
 round to n digits

\end{lstlisting}
\section{numerical-methods}
\subsection{advect\_analytic}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/differentiation}
\subsection{derivative1}
${}$
\begin{lstlisting}
 first derivative on variable mesh
 second order accurate

\end{lstlisting}
\subsection{derivative2}
${}$
\begin{lstlisting}
 second derivative on a variable mesh

\end{lstlisting}
\section{numerical-methods}
\subsection{diffuse\_analytic}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-difference}
\subsection{cdiff}
${}$
\begin{lstlisting}
 differences of columns of X
 degree  = 1 : central first order differences
 degreee = 2 : central second order differences

\end{lstlisting}
\subsection{cdiffb}
${}$
\begin{lstlisting}
 differences of columns of X
 degree  = 1 : central first order differences
 degreee = 2 : central second order differences
 TODO use difference matrix function for simplicity

\end{lstlisting}
\subsection{central\_difference}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cmean}
${}$
\begin{lstlisting}
 single gaussian smoothing step with kernel 1/4*[1,2,1]

\end{lstlisting}
\subsection{cmean2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derivative\_matrix\_1\_1d}
${}$
\begin{lstlisting}
 finite difference matrix of first derivative in one dimensions
 n : number of grid points
 h = L/(n+1) constant step with

 function [D1, d1] = derivative_matrix_1d(n,L,order)

\end{lstlisting}
\subsection{derivative\_matrix\_2\_1d}
${}$
\begin{lstlisting}
 finite derivative matrix of second derivative in one dimension

\end{lstlisting}
\subsection{derivative\_matrix\_2d}
${}$
\begin{lstlisting}
 finite difference derivative matrix in two dimensions

\end{lstlisting}
\subsection{derivative\_matrix\_curvilinear}
${}$
\begin{lstlisting}
 derivative matrix on a curvilinear grid

\end{lstlisting}
\subsection{derivative\_matrix\_curvilinear\_2}
${}$
\begin{lstlisting}
 derivative matrix on a two dimensional curvilinear grid
 the grid has not necessarily to be orthogonal

\end{lstlisting}
\subsection{difference\_kernel}
${}$
\begin{lstlisting}
 difference kernels for equispaced grids
 c.f. Computing the Spectrum of the Confined Hydrogen Atom, Kastner, 2012

\end{lstlisting}
\subsection{diffusion\_matrix\_2d\_anisotropic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{diffusion\_matrix\_2d\_anisotropic2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{directional\_neighbour}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{distmat}
${}$
\begin{lstlisting}
 distance matrix for a 2 dimensional rectangular matrix

\end{lstlisting}
\subsection{downwind\_difference}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gradpde2d}
${}$
\begin{lstlisting}
 objective function gradiend on two dimensional regular grid
 numeric gradient for non-linear least squares optimisation
 of a PDE on a rectangular grid
 x_* = min(f(x))
 f = (v(x) - v(x_*))^2 = f(x) + A dx + O(dx^2)
 a_ij = df_i/dx_j
 

\end{lstlisting}
\subsection{laplacian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{laplacian\_fdm}
${}$
\begin{lstlisting}
 finite difference matrix of the laplacian
 BC

\end{lstlisting}
\subsection{lrmean}
${}$
\begin{lstlisting}
 mean of the left and right element

\end{lstlisting}
\section{numerical-methods/finite-difference/master}
\subsection{fdm\_adaptive\_grid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_adaptive\_refinement\_old}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_assemble\_d1\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_assemble\_d2\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_confinement}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_d\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_h\_unstructured}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_hydrogen\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_mark\_unstructured\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_plot}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_plot\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_refine\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_refine\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_refine\_unstructured\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_schroedinger\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fdm\_schroedinger\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{relocate}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-difference}
\subsection{mid}
${}$
\begin{lstlisting}
 mid point between neighbouring vector elements

\end{lstlisting}
\subsection{pwmid}
${}$
\begin{lstlisting}
 segment end point to segment mid point transformation for regular 1d grids

\end{lstlisting}
\subsection{ratio}
${}$
\begin{lstlisting}
 ratio of two subsequent values

\end{lstlisting}
\subsection{steplength}
${}$
\begin{lstlisting}
 step length of a vector if it were equispaced

\end{lstlisting}
\subsection{swapoddeven}
${}$
\begin{lstlisting}
 swap odd and even elements in a vector

\end{lstlisting}
\subsection{test\_derivative\_matrix\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_derivative\_matrix\_curvilinear}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_difference\_kernel}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{upwind\_difference}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-element}
\subsection{Mesh\_2d\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{Tree\_2d\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_1d\_dphi\_dphi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_1d\_phi\_phi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_2d\_dphi\_dphi\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_2d\_phi\_phi\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_3d\_dphi\_dphi\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{assemble\_3d\_phi\_phi\_java}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{boundary\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{boundary\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{boundary\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{check\_area\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{circmesh}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cropradius}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{display\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{display\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{distort}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{err\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{estimate\_err\_2d\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{example\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{example\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{explode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_2d\_heuristic\_mesh}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_get\_2d\_radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_interpolation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_1d\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_2d\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_3d\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_plot\_confine\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fem\_radial}
${}$
\begin{lstlisting}
 adaptive grid
 constant grid

\end{lstlisting}
\subsection{flip\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{get\_mesh\_arrays}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hashkey}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-element/int}
\subsection{int\_1d\_gauss}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_5}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_lobatto}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_gauss\_n}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_5}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_7}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_1d\_nc\_7\_hardy}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_12}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_13}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_16}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_19}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_25}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_33}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_7}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_gauss\_9}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_nc\_10}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_nc\_15}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_nc\_21}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_nc\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_2d\_nc\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_11}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_14}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_15}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_24}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_45}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_gauss\_5}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_nc\_11}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_nc\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_nc\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{int\_3d\_nc\_8}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-element}
\subsection{interpolation\_matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mark}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mark\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mesh\_1d\_uniform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mesh\_3d\_uniform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mesh\_interpolate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{neighbour\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{old}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pdeeig\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pdeeig\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pdeeig\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{polynomial\_derivative\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{potential\_const}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{potential\_coulomb}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{potential\_harmonic\_oscillator}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{project\_circle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{project\_rectangle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_1d\_2\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_1d\_2\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_1d\_2\_5}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{promote\_1d\_2\_6}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quadrilaterate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{recalculate\_regularity\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{refine\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{refine\_2d\_21}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{refine\_2d\_structural}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{regularity\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{regularity\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{regularity\_3d}
${}$
\begin{lstlisting}
{	T = [1 2 3 4];
}

\end{lstlisting}
\subsection{relocate\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_circmesh}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_hermite}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{tri\_assign\_points}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{triangulation\_uniform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vander\_1d}
${}$
\begin{lstlisting}
 van der Monde matrix

\end{lstlisting}
\subsection{vanderd\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{vanderi\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/finite-volume/@Advection}
\subsection{Advection}
${}$
\begin{lstlisting}
 FVM treatment of the Advection equation

\end{lstlisting}
\subsection{dot\_advection}
${}$
\begin{lstlisting}
 advection equation

\end{lstlisting}
\section{numerical-methods/finite-volume/@Burgers}
\subsection{burgers\_split}
${}$
\begin{lstlisting}
 viscous Burgers' equation,
 mixed analytic and numerical derivative in frequency space
 by splitting sheme
 u_t = -(0.5*u^2)_x + c*u_xx

\end{lstlisting}
\subsection{dot\_burgers\_fdm}
${}$
\begin{lstlisting}
 viscous burgers' equation
 u_t = -d/dx (1/2*u^2) + c d^2/dx^2 u_xx

\end{lstlisting}
\subsection{dot\_burgers\_fft}
${}$
\begin{lstlisting}
 viscous Burgers' equation in frequency space
 u_t + (0.5*u^2)_x = c*u_xx

\end{lstlisting}
\section{numerical-methods/finite-volume/@Finite\_Volume}
\subsection{Finite\_Volume}
${}$
\begin{lstlisting}
 finite volume method for partial differential equations 1+1 dimensions
 (time and space)


\end{lstlisting}
\subsection{apply\_bc}
${}$
\begin{lstlisting}

 apply boundary conditions

\end{lstlisting}
\subsection{solve}
${}$
\begin{lstlisting}
 solve the the PDE by successively stepping in time
 this is a trivial implmentation with constant step length
 severity of diffusive error depends on dt/dx-ratio
 stability depends on wave height
			printf('Progress %2.1f%% %2.1fs\n',100*(t-Ti(1))/(Ti(2)-Ti(1)),t_real);

\end{lstlisting}
\subsection{step\_split\_strang}
${}$
\begin{lstlisting}
 step in time, treat inhomogeneous part by Strang splitting 
 this scheme is not suitable for stationary solutions, for example
 steady shallow water flow

\end{lstlisting}
\subsection{step\_unsplit}
${}$
\begin{lstlisting}

 step in time, without splitting the inhomogeneous term

\end{lstlisting}
\section{numerical-methods/finite-volume/@Flux\_Limiter}
\subsection{Flux\_Limiter}
${}$
\begin{lstlisting}
 class of flux limiters

\end{lstlisting}
\subsection{beam\_warming}
${}$
\begin{lstlisting}
 beam warming sheme
 low resolution
 note: works only if sign of eigenvalues point into the same direction according to RL

\end{lstlisting}
\subsection{fromm}
${}$
\begin{lstlisting}
 fromme limiter
 low res

\end{lstlisting}
\subsection{lax\_wendroff}
${}$
\begin{lstlisting}
 lax wendroff scheme
 second order accurate, but no tvd
 this is effectively not a limiter
 eq. 6.39 in randall, leveque

\end{lstlisting}
\subsection{minmod}
${}$
\begin{lstlisting}
 min-mod schock limiter

\end{lstlisting}
\subsection{monotized\_central}
${}$
\begin{lstlisting}
 monotonized central flux limiter

\end{lstlisting}
\subsection{muscl}
${}$
\begin{lstlisting}
 muscl flux limiter

\end{lstlisting}
\subsection{superbee}
${}$
\begin{lstlisting}
 superbee limiter

\end{lstlisting}
\subsection{upwind}
${}$
\begin{lstlisting}
 godunov scheme
 godunov, first order accurate

\end{lstlisting}
\subsection{vanLeer}
${}$
\begin{lstlisting}
 van Leer limiter

\end{lstlisting}
\section{numerical-methods/finite-volume/@KDV}
\subsection{dot\_kdv\_fdm}
${}$
\begin{lstlisting}
 korteweg de vries equation
 u_t + (0.5*u^2)_x = c*u_xxx

\end{lstlisting}
\subsection{dot\_kdv\_fft}
${}$
\begin{lstlisting}
 korteweg de vries equation
 compute derivatives in frequency space
 u_t + (0.5*u^2)_x = c*u_xxx

\end{lstlisting}
\subsection{kdv\_split}
${}$
\begin{lstlisting}
 korteweg de vries equation in frequency space,
 derivative treated by splitting scheme

\end{lstlisting}
\section{numerical-methods/finite-volume/@Reconstruct\_Average\_Evolve}
\subsection{Reconstruct\_Average\_Evolve}
${}$
\begin{lstlisting}
 Reconstruct Average Evolve Finite Volume Method for treatment of 1+1D pdes

 McCronack Scheme
 err = O(dt^2) + O(dx^2), except as discontinuities
 error:
	h_xxx(3:end-2) = 1/dx^3*( -0.5*h(1:end-4) + h(2:end-3) - h(4:end-1)  + 0.5*h(5:end) );
	th = -1/6*dx^2*qh_.*(1 - (qh_*dt/dx).^2).*h_xxx;

\end{lstlisting}
\subsection{advect\_highres}
${}$
\begin{lstlisting}
 single time step for the reconstruct evolve algorithm

\end{lstlisting}
\subsection{advect\_lowress}
${}$
\begin{lstlisting}
 single time step
 low resolution

\end{lstlisting}
\section{numerical-methods/finite-volume}
\subsection{Godunov}
${}$
\begin{lstlisting}
 Godunov, upwind method for systems of pdes

\end{lstlisting}
\subsection{Lax\_Friedrich}
${}$
\begin{lstlisting}
 Lax-Friedrich-Method
 for hyperbolic conservation laws
 err = O(dt) + O(dx)
 |a dt/dx| < 1

\end{lstlisting}
\subsection{Measure}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{Roe}
${}$
\begin{lstlisting}
 non linear roe solver for the SWE (randall, leveque 15.3.1)

 The roe solver guarantess:
 - A is diagonalisable with real eigenvalues (15.12)
 - can be determined by a closed formula
 - is an efficient replacement for true Rieman solver

\end{lstlisting}
\subsection{fv\_swe}
${}$
\begin{lstlisting}
 wrapper for solving SWE

\end{lstlisting}
\subsection{staggered\_euler}
${}$
\begin{lstlisting}
 forward euler method with staggered grid

\end{lstlisting}
\subsection{staggered\_grid}
${}$
\begin{lstlisting}
 staggered grid approximation to the SWE

\end{lstlisting}
\section{numerical-methods}
\subsection{grid2quad}
${}$
\begin{lstlisting}
 extract rectangular elements of a structured grid
 in form of an unstructured quad-mesh format

\end{lstlisting}
\section{numerical-methods/integration}
\subsection{cumintL}
${}$
\begin{lstlisting}
 cumulative integral from left to right

\end{lstlisting}
\subsection{cumintR}
${}$
\begin{lstlisting}
 cumulative integral from right to left

\end{lstlisting}
\subsection{cumint\_trapezoidal}
${}$
\begin{lstlisting}
 integrate y along x with the trapezoidal rule

\end{lstlisting}
\subsection{int\_trapezoidal}
${}$
\begin{lstlisting}
 integrate y along x with the trapezoidal rule

\end{lstlisting}
\section{numerical-methods/interpolation/@Kriging}
\subsection{Kriging}
${}$
\begin{lstlisting}
 class for Kriging interpolation

\end{lstlisting}
\subsection{estimate\_semivariance}
${}$
\begin{lstlisting}
 estimate the parameter of the semivariance model for Kriging interpolation
		% set up the regression matrix and solve for parameters

\end{lstlisting}
\subsection{interpolate\_}
${}$
\begin{lstlisting}
 interpolate with Krieging method

 this function may interpolate several quantities per coordinate,
 using the same variogram, if the semivariance of the quantities differs,
 the user may prefer to estimate the semivariance and interpolate each quantity
 individually

 Xs  : source point coordinates
 Vs  : value at source points
 Xt  : targe point coordinates
 Vt  : value at target points
 E2t : squared interpolation error at target points

\end{lstlisting}
\section{numerical-methods/interpolation/@RegularizedInterpolator1}
\subsection{RegularizedInterpolator1}
${}$
\begin{lstlisting}
 class for regularized interpolation (Thikonov) on a 1D mesh

\end{lstlisting}
\subsection{init}
${}$
\begin{lstlisting}
 initialize the interpolator with a set of sampling points

\end{lstlisting}
\section{numerical-methods/interpolation/@RegularizedInterpolator2}
\subsection{RegularizedInterpolator2}
${}$
\begin{lstlisting}
 class for regularized interpolation on an unstructures mesh (interpolation)

\end{lstlisting}
\subsection{init}
${}$
\begin{lstlisting}
 initialize the interpolator with a set of point samples

\end{lstlisting}
\section{numerical-methods/interpolation/@RegularizedInterpolator3}
\subsection{RegularizedInterpolator3}
${}$
\begin{lstlisting}
 class for regularized interpolation (Tikhonov) on a triangulation
 (unstructured mesh)

\end{lstlisting}
\subsection{init}
${}$
\begin{lstlisting}
 initialize the interpolator with a set of sampling points

\end{lstlisting}
\section{numerical-methods/interpolation}
\subsection{IDW}
${}$
\begin{lstlisting}
 spatial averaging by inverse distance weighting

\end{lstlisting}
\subsection{IPoly}
${}$
\begin{lstlisting}
 polynomial interpolation class

\end{lstlisting}
\subsection{IRBM}
${}$
\begin{lstlisting}
 interpolate by the radial basis function method
			fprintf(1,'Progress IRBM: %d%%\n',round(100*idx/size(Xi,1)));

\end{lstlisting}
\subsection{ISparse}
${}$
\begin{lstlisting}
 sparse interpolation class

\end{lstlisting}
\subsection{Inn}
${}$
\begin{lstlisting}
 nearest neighbour interpolation

\end{lstlisting}
\subsection{Interpolator}
${}$
\begin{lstlisting}
 interpolator super-class
				fprintf(1,'Progress: %f%% %fs\n',100*idx/size(Xt,1),t);

\end{lstlisting}
\subsection{fixnan}
${}$
\begin{lstlisting}
 fill nan-values in vector with gaps

\end{lstlisting}
\subsection{idw1}
${}$
\begin{lstlisting}
 spatial average ny inverse distance weighting

\end{lstlisting}
\subsection{idw2}
${}$
\begin{lstlisting}
 spatial average by inverse distance weighting

\end{lstlisting}
\subsection{inner2outer}
${}$
\begin{lstlisting}
 linear interpolation of segment mit point to grid points at segment ends
 assumes equal grid spacing

\end{lstlisting}
\subsection{inner2outer2}
${}$
\begin{lstlisting}
 interpolate from element (segment) centres to edge points

\end{lstlisting}
\subsection{interp1\_circular}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{interp1\_limited}
${}$
\begin{lstlisting}
 interpolate values, but not beyond a certain distance
 this function is idempotent, i.e. it will not extrapolate over into gaps
 exceedint the limit and thus not spuriously extend the series when called a second time on the same data

\end{lstlisting}
\subsection{interp1\_man}
${}$
\begin{lstlisting}
 interpolate

\end{lstlisting}
\subsection{interp1\_piecewise\_linear}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{interp1\_save}
${}$
\begin{lstlisting}
 make interpolation save to round off errors
 the matlab internal interpolation suffers from rounding errors, which
 are unacceptable when values of X and Y are large (for example UTm coordinates)
 this normalization prevents this

\end{lstlisting}
\subsection{interp1\_slope}
${}$
\begin{lstlisting}
 quadratic interpolation returning value and derivative(s)

\end{lstlisting}
\subsection{interp1\_smooth}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{interp1\_unique}
${}$
\begin{lstlisting}
 matlab fails to interpolate, when x values are not unique
 this function makes the values unique before use

\end{lstlisting}
\subsection{interp2\_man}
${}$
\begin{lstlisting}
 nearest neighbour interpolation in two dimensions

\end{lstlisting}
\subsection{interp\_angle}
${}$
\begin{lstlisting}
 interpolate an angle

\end{lstlisting}
\subsection{interp\_fourier}
${}$
\begin{lstlisting}
 interpolation by the fourier method

\end{lstlisting}
\subsection{interp\_fourier\_batch}
${}$
\begin{lstlisting}
 batch interpolation by the fourier interpolation

\end{lstlisting}
\subsection{interp\_sn}
${}$
\begin{lstlisting}
 interpolate along streamwise coordinates
 This gives similar result to setting aspect ratio for sN to infinity,
 but not quite,as the input point set is not dense (scale for sN to infinity does not work)
		sdx  = sdx(sdx_); 

\end{lstlisting}
\subsection{interp\_sn2}
${}$
\begin{lstlisting}
 interpolation in streamwise coordinates

\end{lstlisting}
\subsection{interp\_sn3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{interp\_sn\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{limit\_by\_distance\_1d}
${}$
\begin{lstlisting}
 smooth subsequent values along a curve such that
	v(x0+dx) < v(x0) + (ratio-1)*dx
 if v is the edge length in a resampled polygon, then v_i/v_(i+1) < ratio
 	ratio^1 = exp(a*1)

\end{lstlisting}
\subsection{resample1}
${}$
\begin{lstlisting}
 interpolation along a parametric curve with variable step width

\end{lstlisting}
\subsection{resample\_d\_min}
${}$
\begin{lstlisting}
 resample a function

\end{lstlisting}
\subsection{resample\_vector}
${}$
\begin{lstlisting}
 resample a track so that velocity vectors do not run into each other

\end{lstlisting}
\subsection{test\_interp1\_limited}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods}
\subsection{inverse\_complex}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{maccormack\_step}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{minmod}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/multigrid}
\subsection{mg\_interpolate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mg\_restrict}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/ode/@BVPS\_Characteristic}
\subsection{BVPS\_Characteristic}
${}$
\begin{lstlisting}
 solve coupled first- and second-order 1D boundary-value problems

\end{lstlisting}
\subsection{assemble1\_A}
${}$
\begin{lstlisting}
 assemble the discretisation matrix for a first order ode
 (mean component, zero frequency)

\end{lstlisting}
\subsection{assemble1\_A\_Q}
${}$
\begin{lstlisting}
 assemble the discretisation matrix for a first order ode
 (mean component, zero frequency)

\end{lstlisting}
\subsection{assemble2\_A}
${}$
\begin{lstlisting}
 assemble the discretisation matrix for a second-order ode
 (non-zero frequency component)

\end{lstlisting}
\subsection{assemble\_AA}
${}$
\begin{lstlisting}
 assemble the discretisation matrix for each channel
 iteratively calls assembly for each frequency components

\end{lstlisting}
\subsection{assemble\_AAA}
${}$
\begin{lstlisting}
 assemble the discretisation matrix for the entire network
 iteratively calls assembly for each channel

\end{lstlisting}
\subsection{assemble\_Ic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bvp1c}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{check\_arguments}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{couple\_junctions}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derivative}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{init}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{inner2outer\_bvp2c}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{reconstruct}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{resample}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{solve}
${}$
\begin{lstlisting}
 solve system of non-linear second order odes (in more than one variable)
 as boundary value problems

 odefun provides ode coefficients c:
 c(x,1) y''(x) + c(x,2) y'(x) + c(x,3) y = c(x,4)
    c_1 y"     + c_2 y'       + c_3 y + c_4 = c_4

 subject to the boundary conditions
 bcfun provides v and p and optionally q, so that:

 b_1 y + b_2 y' = f
    q(x,1)*( p(x,1) y_l(x) + p(x,2)  y_l'(x)
  + q(x,2)*( p(x,1) y_r(x) + p(x,2) y_r'(x)    = v(x)
 where q weighs the waves travelling from left to right and right to left (default [1 1])

\end{lstlisting}
\subsection{test\_assemble1\_A}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_assemble2\_A}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/ode/@Time\_Stepper}
\subsection{Time\_Stepper}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{solve}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/ode}
\subsection{bvp2fdm}
${}$
\begin{lstlisting}
 solve system of non-linear second order odes (in more than one variable)
 as boundary value problems by the finite difference method

 odefun provides ode coefficients c:
 c(x,1) y''(x) + c(x,2) y'(x) + c(x,3) y = c(x,4)
  c_1 y" + c_2 y' + c_3 y + c_4 = 0

 subject to the boundary conditions
 bcfun provides v and p and optionally q, so that:

 b_1 y + b_2 y' = f
    q(x,1)*( p(x,1) y_l(x) + p(x,2)  y_l'(x)
  + q(x,2)*( p(x,1) y_r(x) + p(x,2) y_r'(x)    = v(x)
 where q weighs the waves travelling from left to right and right to left (default [1 1])

\end{lstlisting}
\subsection{bvp2wavetrain}
${}$
\begin{lstlisting}
 solve second order boundary value problem by repeated integration

\end{lstlisting}
\subsection{bvp2wavetwopass}
${}$
\begin{lstlisting}
 two pass solution for the linearised wave equation
 solve first for the wave number k, and then for y

\end{lstlisting}
\subsection{ivp\_euler\_forward}
${}$
\begin{lstlisting}
 solve intial value problem by the euler forward method

\end{lstlisting}
\subsection{ivp\_euler\_forward2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ivprk2}
${}$
\begin{lstlisting}
 solve initial value problem by the two step runge kutta method

\end{lstlisting}
\subsection{ode2\_matrix}
${}$
\begin{lstlisting}
 transformation matrix of second order ode
 to left and right going wave

 c = odefun(x)
 c1 y'' + c2' y + c3 y == 0
 y = y_p + y_m, left and right going wave
 d/dx [y_p, y_m] = A*[y_m, y_p]

\end{lstlisting}
\subsection{ode2characteristic}
${}$
\begin{lstlisting}
 second order odes 
 transmittded and reflected wave

\end{lstlisting}
\subsection{step\_trapezoidal}
${}$
\begin{lstlisting}
 single trapezoidal step

\end{lstlisting}
\subsection{test\_bvp2}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/optimisation}
\subsection{aitken\_iteration}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{anderson\_iteration}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{armijo\_stopping\_criterion}
${}$
\begin{lstlisting}
 armijo stopping criterion for optimizations

\end{lstlisting}
\subsection{astar}
${}$
\begin{lstlisting}
 astar path finding alforithm

\end{lstlisting}
\subsection{binsearch}
${}$
\begin{lstlisting}
 binary search on a line

\end{lstlisting}
\subsection{bisection}
${}$
\begin{lstlisting}
 bisection

\end{lstlisting}
\subsection{box1}
${}$
\begin{lstlisting}
 test objective function for optimisation routines 

\end{lstlisting}
\subsection{box2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cauchy}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cauchy2}
${}$
\begin{lstlisting}
 solve non-linear system by cuachy's method
 slower than quadratic optimisation, but does not require a hessian
 fun : objective function, returns
	f  : scalar, objective function value 
	g  : nx1, gradient
 x   : nx1, initial position
 opt : options

\end{lstlisting}
\subsection{directional\_derivative}
${}$
\begin{lstlisting}
 directional (projected) derivative
 d : derivative, highest first
 p : series expansion around x0

\end{lstlisting}
\subsection{dud}
${}$
\begin{lstlisting}
 optimization by the dud algorithm

\end{lstlisting}
\subsection{extreme3}
${}$
\begin{lstlisting}
 extract maxima by quadratic approximation from sampled function val(t)
 intended to be called after [mval, mid] = max(val) for refinement of
 locatian and maximum

 input
 t    : sampling time (uniformly spaced)
 v    : values at sampling times
 ouput:
 tdx  : index where extremum should be computed
 t0   : location of the extremum
 val0 : value of extremum

 v'(dt0) = 0 and v''(dt0) determines type of extremum

\end{lstlisting}
\subsection{extreme\_quadratic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ftest}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fzero\_bisect}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fzero\_newton}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{grad}
${}$
\begin{lstlisting}
 numerical gradient

\end{lstlisting}
\subsection{hessian}
${}$
\begin{lstlisting}
 numerical hessian

\end{lstlisting}
\subsection{hessian\_from\_gradient}
${}$
\begin{lstlisting}
 numerical hessian from gradient

\end{lstlisting}
\subsection{hessian\_projected}
${}$
\begin{lstlisting}
 numerical hessian projected to one dimenstion

\end{lstlisting}
\subsection{line\_search}
${}$
\begin{lstlisting}
 bisection routine

\end{lstlisting}
\subsection{line\_search2}
${}$
\begin{lstlisting}
 bisection method

 fun : objective funct
 x0  : start value
 f0  : objective function value at x0
 g   : gradient at x0
 p   : search direction from x0 (p = g for steepest descend)
 h   : initial step length (default 1)
 lb  : lower bound for x
 up  : upper bound for x

\end{lstlisting}
\subsection{line\_search\_polynomial}
${}$
\begin{lstlisting}
 polynomial line search
 fun : objective funct
 x0  : start value
 f0  : objective function value at x0
 g   : gradient at x0
 dir : search direction from x0 (p = g for steepest descend)
 h   : initial step length (default 1)
 lb  : lower bound for x
 up  : upper bound for x

\end{lstlisting}
\subsection{line\_search\_polynomial2}
${}$
\begin{lstlisting}
 cubic line search
 fun : objective funct
 x0  : start value
 f0  : objective function value at x0
 g   : gradient at x0
 dir : search direction from x0 (p = g for steepest descend)
 h   : initial step length (default 1)
 lb  : lower bound for x
 up  : upper bound for x

\end{lstlisting}
\subsection{line\_search\_quadratic}
${}$
\begin{lstlisting}
 quadratic line search
 fun : objective funct
 x0  : start value
 f0  : objective function value at x0
 g   : gradient at x0
 dir : search direction from x0 (p = g for steepest descend)
 h   : initial step length (default 1)
 lb  : lower bound for x
 up  : upper bound for x

\end{lstlisting}
\subsection{line\_search\_quadratic2}
${}$
\begin{lstlisting}
 quadratic line search

\end{lstlisting}
\subsection{line\_search\_wolfe}
${}$
\begin{lstlisting}
 line search by wolfe method
 c.f.: OPTIMIZATION THEORY AND METHODS - Nonlinear Programming, Sun, Yuan

\end{lstlisting}
\subsection{ls\_bgfs}
${}$
\begin{lstlisting}
 least squares by the bgfs method

\end{lstlisting}
\subsection{ls\_broyden}
${}$
\begin{lstlisting}
 least squares by the broyden method
 for rectangular / non symmetric systems
	Numerical  Optimization nocedal
	Practical  Methods  of  Optimization fletcher
 c.f. gerber 1981
 c.f. fletcher 1978 (more advanced, not used here)
 c.f. Kelley 1999 ch. 4

 BGFS:
 Broyden 1965
 Fletcher 1970
 Goldfarb 1970
 Shanno 1970

\end{lstlisting}
\subsection{ls\_generalized\_secant}
${}$
\begin{lstlisting}
 least squares by the secant method
 Barnes, 1965
 Wolfe, 1959
 Fletcher 1980, 6.3
 seber 2003
 gerber

\end{lstlisting}
\subsection{nlcg}
${}$
\begin{lstlisting}
 non-linear conjugate gradient
 input:
 x   : nx1 start vectort
 opt : struct options
 fdx : gradient constraint

\end{lstlisting}
\subsection{nlls}
${}$
\begin{lstlisting}
 non-linear least squares

\end{lstlisting}
\subsection{picard}
${}$
\begin{lstlisting}
 picard iteration

\end{lstlisting}
\subsection{poly\_extrema}
${}$
\begin{lstlisting}
 extrema of a polynomial

\end{lstlisting}
\subsection{quadratic\_function}
${}$
\begin{lstlisting}
 evaluate quadratic function in higher dimensions

\end{lstlisting}
\subsection{quadratic\_programming}
${}$
\begin{lstlisting}
 optimize by quadratic programming

\end{lstlisting}
\subsection{quadratic\_step}
${}$
\begin{lstlisting}
 single step of the quadratic programming

\end{lstlisting}
\subsection{rosenbrock}
${}$
\begin{lstlisting}
 rosenbrock test function

\end{lstlisting}
\subsection{sqrt\_heron}
${}$
\begin{lstlisting}
 Heron's method for the square root

\end{lstlisting}
\subsection{test\_directional\_derivative}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_dud}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fzero\_newton}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_line\_search\_quadratic2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ls\_generalized\_secant}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_nlcg\_6\_order}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_nlls}
${}$
\begin{lstlisting}
	f = w'*(p*abs(x-1).^4) + w'*(1-p)*abs(x-1).^2;

\end{lstlisting}
\section{numerical-methods/pde}
\subsection{laplacian2d\_fundamental\_solution}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods/piecewise-polynomials}
\subsection{Hermite1}
${}$
\begin{lstlisting}
 hermite polynomial interpolation in 1d

\end{lstlisting}
\subsection{hp2\_fit}
${}$
\begin{lstlisting}

 fit a hermite polynomial
 coefficients are derivative free
 x0  : left point of first segment
 x1  : right point of last segment
 n   : number of segments
 x   : sample x-value
 val : sample y-value
 c   : coefficients (values at points, no derivatives)

\end{lstlisting}
\subsection{hp2\_predict}
${}$
\begin{lstlisting}
 prediction with pw hermite polynomial
 c are values at support points

\end{lstlisting}
\subsection{hp\_predict}
${}$
\begin{lstlisting}
 predict with piecewise hermite polynomial

\end{lstlisting}
\subsection{hp\_regress}
${}$
\begin{lstlisting}
 fit piecewise hermite polynomial
 coefficients are values and derivatives

\end{lstlisting}
\subsection{lp\_count}
${}$
\begin{lstlisting}
 lagrangian basis for interpolation
 count number of valid samples

\end{lstlisting}
\subsection{lp\_predict}
${}$
\begin{lstlisting}
 lagrangian basis piecwie interpolation, predicor

\end{lstlisting}
\subsection{lp\_regress}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lp\_regress\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{numerical-methods}
\subsection{test\_adams\_bashforth}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{oversampleNZ}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{regression/@PolyOLS}
\subsection{PolyOLS}
${}$
\begin{lstlisting}
 class for polynomial least squares

\end{lstlisting}
\subsection{coefftest}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{detrend}
${}$
\begin{lstlisting}
 detrending by polynomial regression

\end{lstlisting}
\subsection{fit}
${}$
\begin{lstlisting}
 fit a polynomial function
 like polyfit, but returns parameter error estimates
 TODO automatically activate scaleflag

\end{lstlisting}
\subsection{fit\_}
${}$
\begin{lstlisting}
 fit a polynomial function

\end{lstlisting}
\subsection{predict}
${}$
\begin{lstlisting}
 predict polynomial function values

\end{lstlisting}
\subsection{predict\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{slope}
${}$
\begin{lstlisting}
 slope by linear regression

\end{lstlisting}
\section{regression/@PowerLS}
\subsection{PowerLS}
${}$
\begin{lstlisting}
 class for power law regression

\end{lstlisting}
\subsection{fit}
${}$
\begin{lstlisting}
 fit a power law
 like polyfit, but returns parameter error estimates

\end{lstlisting}
\subsection{predict}
${}$
\begin{lstlisting}
 predict with power law
	S2 = diag((A*obj.C)*A');
	L  = Y - S;
	U  = Y + S;

\end{lstlisting}
\subsection{predict\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{regression/@Theil}
\subsection{Theil}
${}$
\begin{lstlisting}
 Kendal-Theil-Sen robust regression

\end{lstlisting}
\subsection{detrend}
${}$
\begin{lstlisting}
 linear detrending of a set of samples by the Theil-Senn Slope

\end{lstlisting}
\subsection{fit}
${}$
\begin{lstlisting}
 fit slope and intercept to a set of sample with the Theil-Sen method
 
 c     : confidence interval c = 2*ns*normcdf(1) for ns-sigma intervals
 param : itercept and slope
 P : confidence interval

\end{lstlisting}
\subsection{predict}
${}$
\begin{lstlisting}
 predict values and confidence intervals with the Theil-Sen method

\end{lstlisting}
\subsection{slope}
${}$
\begin{lstlisting}
 fit the slope with the Theil-Sen method

\end{lstlisting}
\section{regression}
\begin{lstlisting}
linear and non-linear regression

\end{lstlisting}
\subsection{Theil\_Multivariate}
${}$
\begin{lstlisting}
 extension of the Theil-Senn regression to higher dimensions by
 means of the Gauss-Seidel iteration

\end{lstlisting}
\subsection{areg}
${}$
\begin{lstlisting}
 regression using the pth-fraction of samples with smallest residual

\end{lstlisting}
\subsection{ginireg}
${}$
\begin{lstlisting}
 gini regression

\end{lstlisting}
\subsection{hesssimplereg}
${}$
\begin{lstlisting}
 hessian, gradient and objective function value of the simple regression
 rhs = p(1) + p(2) x + eps

\end{lstlisting}
\subsection{l1lin}
${}$
\begin{lstlisting}
 solve ||Ax - b||_L1 by means of linear programming

\end{lstlisting}
\subsection{lsq\_sparam}
${}$
\begin{lstlisting}
 parameter covariance of the least squares regression

 fun : model function for predtiction
 b   : sample values
 f(p) = b
 p   : parameter at point of evaluation (preferably optimum)

\end{lstlisting}
\subsection{polyfitd}
${}$
\begin{lstlisting}
 fit a polynomial of order n to a set of sampled values and sampled values
 of the derivative

 x0 must contain at least for conditioning as otherwise the intercept
 cannot be determined

\end{lstlisting}
\subsection{regression\_method\_of\_moments}
${}$
\begin{lstlisting}
 fit linear function ||a b x = y||_L2 by the method of moments
 y+eps = alpha + beta*x

\end{lstlisting}
\subsection{robustlinreg}
${}$
\begin{lstlisting}
 fit a linear function by splitting the x-values at their median
 	(med(y_left) - med(y_right))/(med(x_left)-med(x_right)
 this approach performs poorly compared to the theil-senn operator

\end{lstlisting}
\subsection{theil2}
${}$
\begin{lstlisting}
 Theil senn-estimator for two dimensions (glm)

\end{lstlisting}
\subsection{theil\_generalised}
${}$
\begin{lstlisting}
 generalization of the Theil-Senn operator to higher dimensions,
 for arbitrary functions such as polynomials and multivariate regression
 either higher order polynomials or glm
 c.f. "On theil's fitting method", Pegoraro, 1991

\end{lstlisting}
\subsection{total\_least\_squares}
${}$
\begin{lstlisting}
 total least squares

\end{lstlisting}
\subsection{weighted\_median\_regression}
${}$
\begin{lstlisting}
 weighted median regression 
 c.f. Scholz, 1978

\end{lstlisting}
\section{set-theory}
\subsection{issubset}
${}$
\begin{lstlisting}
 test if set B is subset of A in O(n)-runtime

 A : first set
 B : second set
 P : set of primes (auxiliary)

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{shuffle\_index}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing}
\subsection{asymwin}
${}$
\begin{lstlisting}
 creates asymmetrical filter windows
 filter will always have negative weights

\end{lstlisting}
\section{signal-processing/autocorrelation}
\subsection{acf\_radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{acfar1}
${}$
\begin{lstlisting}
 Autocorrelation function of the finite AR1 process

 a_k = 1/(n-k)sum x_ix_i+1 + (xi + xi+k)mu + mu^2
     = r^k + 1/n sum_ij + 1/n
	pause

\end{lstlisting}
\subsection{acfar1\_2}
${}$
\begin{lstlisting}
 autocorrelation of the ar1 process

\end{lstlisting}
\subsection{acfar2}
${}$
\begin{lstlisting}
 impulse response of the ar2 process

\end{lstlisting}
\subsection{acfar2\_2}
${}$
\begin{lstlisting}
 autocorrelation of the ar2 process
 X_i + a1 X_i-1 + a2 X_i-2 = 0

\end{lstlisting}
\subsection{ar1\_cutoff\_frequency}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ar1\_effective\_sample\_size}
${}$
\begin{lstlisting}
 effective sample size correction for autocorrelated series

\end{lstlisting}
\subsection{ar1\_mse\_mu\_single\_sample}
${}$
\begin{lstlisting}
 standard error of a single sample of an ar1 correlated process

\end{lstlisting}
\subsection{ar1\_mse\_pop}
${}$
\begin{lstlisting}
 variance of the population mean of a single realisation around zero

 E[(mu_N-0)^2] = E[mu_N^]


\end{lstlisting}
\subsection{ar1\_mse\_range}
${}$
\begin{lstlisting}
 mean standard error of the mean of a range of values taken from an ar1 process

\end{lstlisting}
\subsection{ar1\_spectrum}
${}$
\begin{lstlisting}
 spectrum of the ar1 process

\end{lstlisting}
\subsection{ar1\_to\_tikhonov}
${}$
\begin{lstlisting}
 convert ar1 correlation to tikhonovs lambda

\end{lstlisting}
\subsection{ar1\_var\_factor}
${}$
\begin{lstlisting}
 variance correction factor for an autocorrelated finite process
 n   : [1 .. inf] population size
 m   : [1 .. n]   samples size
 rho : [ -1 < rho < 1 (for convergence) ] correlation of samples

\end{lstlisting}
\subsection{ar1\_var\_factor\_}
${}$
\begin{lstlisting}
 variance of an autocorrelated finite process

\end{lstlisting}
\subsection{ar1\_var\_range2}
${}$
\begin{lstlisting}
 variance of sub sample starting at the end of the series

 from the finite length first order autocorrelated process

 s2 = 1/m^2 sum_i^m sum_j^m rho^-|i-j|

\end{lstlisting}
\subsection{ar1delay}
${}$
\begin{lstlisting}
 approximate acf by the ar1 process
 acf: autocovariance or autocorrerlation function
 nf : skip first samples (for mixed geometric-arithmetic series (ARMA)

\end{lstlisting}
\subsection{ar1delay\_old}
${}$
\begin{lstlisting}
 autocorrelation of the residual

\end{lstlisting}
\subsection{ar2\_acf2c}
${}$
\begin{lstlisting}
 determine coefficients of the ar2 process from the first two lags of the
 autocorrelation function

\end{lstlisting}
\subsection{ar2conv}
${}$
\begin{lstlisting}
 coefficients of the ar2 process determined from the two leading correlations
 of the acf [1,r1,r2,...]

\end{lstlisting}
\subsection{ar2dof}
${}$
\begin{lstlisting}
 effective samples size for the ar2 process

\end{lstlisting}
\subsection{ar2param}
${}$
\begin{lstlisting}
 ar2 parameter estimation from first two terms of acf

 acf = [1 a1 a2 ...]

\end{lstlisting}
\subsection{autocorr2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_angular}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_bandpass}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_decay\_rate}
${}$
\begin{lstlisting}
 estimate exponential decay of the autocorrelation

\end{lstlisting}
\subsection{autocorr\_effective\_sample\_size}
${}$
\begin{lstlisting}
 effective sample size from acf

\end{lstlisting}
\subsection{autocorr\_fft}
${}$
\begin{lstlisting}
 estimate sample autocorrelation function

\end{lstlisting}
\subsection{autocorr\_forest}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_genton}
${}$
\begin{lstlisting}
 autocorrelation function

\end{lstlisting}
\subsection{autocorr\_highpass}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_lowpass}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_periodic\_additive\_noise}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_periodic\_windowed}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorr\_radial\_hexagonal\_pattern}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{autocorrelation\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing}
\subsection{average\_wave\_shape}
${}$
\begin{lstlisting}
 extract waves with varying length from a wave train and and average their shape

\end{lstlisting}
\subsection{bandpass}
${}$
\begin{lstlisting}
 bandpass filter

\end{lstlisting}
\subsection{bandpass\_continuous\_cdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bartlett}
${}$
\begin{lstlisting}
 Effective sample size factor for bartlett window
 c.f. thiebaux
 c.f spectral analysis-jenkins, eq. (6.3.27)
 c = acf
 note: results seams always to be 1 tac too low
 T : reduction factor for dof
 for ar1 with a = rho^k = exp(-k/L), T = 2L

\end{lstlisting}
\subsection{bin1d}
${}$
\begin{lstlisting}
 bin values of v sampled at x into bins bounded by "edges"
 apply function v to it

\end{lstlisting}
\subsection{bin2d}
${}$
\begin{lstlisting}
 bin values of V sampled at X and Y into the grid structured grid ex,ey
 apply function func to all walues in the bin
 func = mean : default
 func = sum : non-normalized frequency histogram in 2D

\end{lstlisting}
\subsection{binormrnd}
${}$
\begin{lstlisting}
 generate two correlated normally distributed vectors

\end{lstlisting}
\subsection{coherence}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{conv1\_man}
${}$
\begin{lstlisting}
 convolutions with padding

\end{lstlisting}
\subsection{conv2\_man}
${}$
\begin{lstlisting}
 convolution in 2d

\end{lstlisting}
\subsection{conv2z}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{conv30}
${}$
\begin{lstlisting}
 convolve with rectangular window of lenght n
 circular boundaries

\end{lstlisting}
\subsection{conv\_}
${}$
\begin{lstlisting}
 convolution of a with b

\end{lstlisting}
\subsection{conv\_centered}
${}$
\begin{lstlisting}
 convolve x with filter window f
 when length of f is even, this guarantees a symmetric result (no off by on
 displacement) by making the lenght of f odd at first

\end{lstlisting}
\subsection{convz}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{cosexpdelay}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{csmooth}
${}$
\begin{lstlisting}
 smooth recursively with [1,2,1]/4 kernel
 function x = csmooth(x,n,p,circ)

\end{lstlisting}
\subsection{daniell\_window}
${}$
\begin{lstlisting}
 Daniell window for smoothing the power spectrum
 c.f. Daniell 1946
 Bloomfield 2000
 meko 2015

\end{lstlisting}
\subsection{db2neper}
${}$
\begin{lstlisting}
 convert decibel to neper

\end{lstlisting}
\subsection{db2power}
${}$
\begin{lstlisting}
 power ratio from db

\end{lstlisting}
\subsection{derive\_bandpass\_continuous\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_danielle\_weight}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{derive\_limit\_0\_acfar}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{detect\_peak}
${}$
\begin{lstlisting}
 detect peaks in a vector
 requires function value to fall to p*max before new value is allowed

\end{lstlisting}
\subsection{determine\_phase\_shift}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{determine\_phase\_shift1}
${}$
\begin{lstlisting}
 average phase and phase shift per time step of a train of waves

\end{lstlisting}
\subsection{doublesum\_ij}
${}$
\begin{lstlisting}
 double sum of r^i

\end{lstlisting}
\subsection{effective\_mask\_size}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{effective\_sample\_size\_to\_ar1}
${}$
\begin{lstlisting}
 convert effective sample size to ar1 correlation

\end{lstlisting}
\subsection{fcut2Lw\_gausswin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fcut\_gausswin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{filt\_hodges\_lehman}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing/filters}
\subsection{circfilt2}
${}$
\begin{lstlisting}
 smooth (filter) the  2D image z with a circular disk of radius nf
 apply periodic boundary conditions

\end{lstlisting}
\subsection{filter1}
${}$
\begin{lstlisting}
 filter along one dimension

\end{lstlisting}
\subsection{filter2}
${}$
\begin{lstlisting}
 filter columns of x (matlab does only support vector input)

\end{lstlisting}
\subsection{filter\_}
${}$
\begin{lstlisting}
 invalidate values that exceed n-times the robust standard deviation

\end{lstlisting}
\subsection{filter\_r\_to\_f0}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{filter\_rho\_to\_f0}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{filter\_twosided}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{filteriir}
${}$
\begin{lstlisting}
 filter adcp t-n data over time

 v : nz,nt   : values to be filtered
 H : nt,1    : depth of ensemble
 last : nt,1 : last bin above bottom that can be sampled without side lobe interference
 nf : scalar : number of reweighted iterations

 when samples 
 - distance to bed is reference (advantageous for near-bed suspended transport)
 TODO for wash load: distance to surface is more relevant
 interpolate depending on z

 when depth changes, neighbouring indices do not correspond to same relative position in the water column
 relative poisition in the colum (s-coordinate) smoothes values
 near the bed: absolute distance to bed is chosen
 near surface: absolute distance to surface is chosen
 -> cubic transformation of index

 faster and avoid alising (smoothing along z)
	resample ensemble to same number of bins in S -> filter -> resample back
	use nonlinear transform z-s coordinates
 -> resampling has to be local (Hi -> H-filtered)

 filtered profile coordinates to sample coordinates
 	zf -> zi (special transform)
 corresponding indices and fractions
 filtration step (update of hf and vf)
 sample coordinates to updated profile coordinates
 (the inverse step is actually not necessary)
 write filtered value

\end{lstlisting}
\subsection{filterp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{filterp1}
${}$
\begin{lstlisting}
 fir filter with some fancy extras

\end{lstlisting}
\subsection{filterstd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gaussfilt2}
${}$
\begin{lstlisting}
 smooth (filter) the  2D image z with a gaussian window
 apply periodic boundary conditions

\end{lstlisting}
\subsection{lowpass\_discrete}
${}$
\begin{lstlisting}
 design coefficients of a low pass filter with specified cut of frequency
 and sampling period
 alalogue low pass with pole at s=-omega_c=1/tau=1/RC
 Ha = tau/(tau + s) = 1/(1 + omega_c*s)

\end{lstlisting}
\subsection{meanfilt2}
${}$
\begin{lstlisting}
 filter with a rectangular window along both dimensions

\end{lstlisting}
\subsection{medfilt1\_man}
${}$
\begin{lstlisting}
 moving median filter, supports columnwise operation

\end{lstlisting}
\subsection{medfilt1\_man2}
${}$
\begin{lstlisting}
 moving median filter with special treatment of boundaries

\end{lstlisting}
\subsection{medfilt1\_padded}
${}$
\begin{lstlisting}
 median filter with padding

\end{lstlisting}
\subsection{medfilt1\_reduced}
${}$
\begin{lstlisting}
 median filter with padding

\end{lstlisting}
\subsection{trifilt1}
${}$
\begin{lstlisting}
 filter with triangular window
 trifilt1 is ident to twice applying rectfilt1 (meanfilt1) with half the domain size
 note : inifnitely many convolution yield a gaussian

\end{lstlisting}
\subsection{trifilt2}
${}$
\begin{lstlisting}
 filter with a triangular window along both dimensions

\end{lstlisting}
\section{signal-processing}
\subsection{firls\_man}
${}$
\begin{lstlisting}
 design finite impulse response filter by the least squares method

\end{lstlisting}
\subsection{fit\_spectral\_density}
${}$
\begin{lstlisting}
 fit (spectral) densities

\end{lstlisting}
\subsection{fit\_spectral\_density\_2d}
${}$
\begin{lstlisting}
 fit spectral densities

\end{lstlisting}
\subsection{fit\_spectral\_density\_radial}
${}$
\begin{lstlisting}
 fit spectral densities

\end{lstlisting}
\subsection{flattopwin}
${}$
\begin{lstlisting}
 the flat top window

\end{lstlisting}
\subsection{frequency\_response\_boxcar}
${}$
\begin{lstlisting}
 frquency response of a boxcar filter

\end{lstlisting}
\subsection{freqz\_boxcar}
${}$
\begin{lstlisting}
 frequncy response of a boxcar filter

\end{lstlisting}
\subsection{gaussfilt1}
${}$
\begin{lstlisting}
 filter data series with a gaussian window, assumes periodic bc

\end{lstlisting}
\subsection{hanchangewin}
${}$
\begin{lstlisting}
 hanning window for change point detection

\end{lstlisting}
\subsection{hanchangewin2}
${}$
\begin{lstlisting}
 nanning window for chage point detection

\end{lstlisting}
\subsection{hanwin}
${}$
\begin{lstlisting}
 hanning filter window

\end{lstlisting}
\subsection{hanwin\_}
${}$
\begin{lstlisting}
 hanning filter window

\end{lstlisting}
\subsection{high\_pass\_1d\_simple}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kaiserwin}
${}$
\begin{lstlisting}
 kaiser filter window

\end{lstlisting}
\subsection{kalman}
${}$
\begin{lstlisting}
 Kalman filter

\end{lstlisting}
\subsection{lanczoswin}
${}$
\begin{lstlisting}
 Lanczos window

\end{lstlisting}
\subsection{last}
${}$
\begin{lstlisting}
 lake tail, but for matrices

\end{lstlisting}
\subsection{maxfilt1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{meanfilt1}
${}$
\begin{lstlisting}
 moving average filter with special treatment of the boundaries

\end{lstlisting}
\subsection{mid\_term\_single\_sample}
${}$
\begin{lstlisting}
 variance of single sample, mid term

\end{lstlisting}
\subsection{minfilt1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{minmax}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mu2ar1}
${}$
\begin{lstlisting}
 error variance of the mean of the finite length ar1 process


 (mu)^2 = (sum epsi)^2 = sum_i sum_j eps_i eps_j = sum_ii(rho,n)/n^2
 this has the limit s^2 for rho->1 

\end{lstlisting}
\subsection{mysmooth}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{nanautocorr}
${}$
\begin{lstlisting}
 autocorrelation with nan-values

\end{lstlisting}
\subsection{nanmedfilt1}
${}$
\begin{lstlisting}
 medfilt1, skipping nans

\end{lstlisting}
\subsection{neper2db}
${}$
\begin{lstlisting}
 convert neper to db

\end{lstlisting}
\subsection{oscillator\_noisy}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing/passes}
\subsection{bandpass1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass1d\_fft}
${}$
\begin{lstlisting}
 filter input vector with a spatial (two-sided) bandpass in fourier space

\end{lstlisting}
\subsection{bandpass1d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2}
${}$
\begin{lstlisting}
 bandpass filter

\end{lstlisting}
\subsection{bandpass2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_ideal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_iso}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass\_arg}
${}$
\begin{lstlisting}
 determine correlation coefficient from frequency of mode for the symmetric

\end{lstlisting}
\subsection{bandpass\_f0\_to\_rho}
${}$
\begin{lstlisting}
 correlation coefficient for the pth-order symmetric bandpass filter with
 maximum at f0 (when rho_lp = rho_hp)

\end{lstlisting}
\subsection{bandpass\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass\_max2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass}
${}$
\begin{lstlisting}
 high pass filter

\end{lstlisting}
\subsection{highpass1d\_fft\_cos}
${}$
\begin{lstlisting}
 filter the input vector with a cosine-shaped highpass in frequency space

\end{lstlisting}
\subsection{highpass1d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass2d\_ideal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass2d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass\_arg}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass\_fc\_to\_rho}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass}
${}$
\begin{lstlisting}
 low pass filter

\end{lstlisting}
\subsection{lowpass1d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass1d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2}
${}$
\begin{lstlisting}
 design low pass filter with cutoff-frequency f1

\end{lstlisting}
\subsection{lowpass2d\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_anisotropic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_ideal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass\_arg}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass\_fc\_to\_rho}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass\_iir}
${}$
\begin{lstlisting}
 iir-low pass

\end{lstlisting}
\subsection{lowpass\_iir\_symmetric}
${}$
\begin{lstlisting}
 two-sided iir low pass filter (for symmetry)

\end{lstlisting}
\subsection{lowpassfilter2}
${}$
\begin{lstlisting}
 low-pass filter of data

\end{lstlisting}
\section{signal-processing}
\subsection{peaks\_man}
${}$
\begin{lstlisting}
 peaks of a periodogram

\end{lstlisting}
\section{signal-processing/periodogram}
\subsection{periodogram}
${}$
\begin{lstlisting}
 compute the normalized periodogram

\end{lstlisting}
\subsection{periodogram\_2d}
${}$
\begin{lstlisting}
 compute the normalized periodogram in two dimensions

\end{lstlisting}
\subsection{periodogram\_align}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_angular}
${}$
\begin{lstlisting}
 input:
 	Sxy : nxn
 ouput:
 	Sra : n/2*(pi*n/2)
	angle
 function [Sa,angle,A] = periodogram_angular(Sxy,L,nf)

\end{lstlisting}
\subsection{periodogram\_bartlett}
${}$
\begin{lstlisting}
 estimate the spectral density nonparametrically with Bartlett's method

\end{lstlisting}
\subsection{periodogram\_bootstrap}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_confidence\_interval}
${}$
\begin{lstlisting}
 confidence interval for periodogram values

\end{lstlisting}
\subsection{periodogram\_filter}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_median}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_p\_value}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_qq}
${}$
\begin{lstlisting}
 qq-plot of a spectral density estimate by smoothing against the expected
 beta-density

\end{lstlisting}
\subsection{periodogram\_quantiles}
${}$
\begin{lstlisting}
 quantiles of a periodogram

\end{lstlisting}
\subsection{periodogram\_radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{periodogram\_std}
${}$
\begin{lstlisting}
 standard deviation of a periodogram

\end{lstlisting}
\subsection{periodogram\_test\_periodicity}
${}$
\begin{lstlisting}
 test a periodogram for hidden periodic frequency components
 
 function [p,ratio,maxShat,mdx,fdx,S] = periodogram_test_periodicity(fx,Shat,nf,fmin,fmax,S,mode)

 input:
	fx : frequengcies
	Shat : corresponding periodogram values
      nf   : number of bins to test for periodicity, ignored when S is given
	fmin, fmax : frequency range limits to test
	S    : exact (a priori known theoretical spectral density, must not be estimated from the periodogram)
	mode : automatically set to "exact", when S given
	       inclusive : estimate density by smoothing including the central bin
	       exclusive : estimate density by smoothing  excluding the central bin
	note: inclusive and exclusive lead to different distribution
	      but identical p-values

 TODO pass L and not fx

\end{lstlisting}
\subsection{periodogram\_test\_periodicity\_2d}
${}$
\begin{lstlisting}
 test a periodogram for hidden periodic frequency components
 
 [p,stat,ratio] = periodogram_test_periodicity_2d(b, L, nf, bmsk, fmsk, ns)

 input:
	b    (nx * ny): image to test for presence of hidden periodicities,
             i.e. periodicities where the frequency is not known a priori
      nf   = nfr or [nfx, nfy]
	       radius of circular disk (in number of bins) used for smoothing
             the periodogram to estimate the spectral density,
	       or axes of ellipses for smoothing
	       when b is not square a good choice is nfx/nfy ~ Lx/Ly
      bmsk : mask in real space selecting parts of the image to include in
	       the analysis default is entire image
	       the mask can have non-integer values to feather the borders of the mask
	fmsk : mask in frequency selecting frequencies to test for periodicity
	       default is all frequencies
	       note: when b is real, one half plane can always be excluded
	       because of symmetry. This slightly increases the significance
	ns   : number of samples for the monte-carlo determination of
	       the test statistics, mc is only used when parts of the image are masked
	       otherwise the analytic test statistic is used 

 influence of masking the input file:
 	      - the root-mean-square energy of the ordinates is proportional
	        to the number of unmasked points
	      - values in the periodogram are not any more linearly independent
	        so that the dof of the filter window is not nf^2


\end{lstlisting}
\subsection{periodogram\_test\_stationarity}
${}$
\begin{lstlisting}
 test a periodogram for statoinarity
 note : the method works, but is of little practical use,
 as it requires about 50 periods and a small dx to detect a frequency change by a factor of 2

\end{lstlisting}
\subsection{periodogram\_welsh}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing}
\subsection{polyfilt1}
${}$
\begin{lstlisting}
 polynomial filter,
 can be achieved by iteratively processing the data with
 a mean (zero-order) filter

\end{lstlisting}
\subsection{qmedfilt1}
${}$
\begin{lstlisting}
 medfilt1, after fitting a quadratic polynomial

\end{lstlisting}
\subsection{quadratfilt1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quadratwin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{randar1}
${}$
\begin{lstlisting}
 generate random ar1 process
 e1 = randar1(sigma,p,n,m)

\end{lstlisting}
\subsection{randar1\_dual}
${}$
\begin{lstlisting}
 draw random variables of two corrlated ar1 processes

\end{lstlisting}
\subsection{randar2}
${}$
\begin{lstlisting}
 generate ar2 process

\end{lstlisting}
\subsection{randarp}
${}$
\begin{lstlisting}
 randomly generate the instance of an ar-p process

\end{lstlisting}
\subsection{rectwin}
${}$
\begin{lstlisting}
 rectangular window

\end{lstlisting}
\subsection{recursive\_sum}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{select\_range}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{smooth1d\_parametric}
${}$
\begin{lstlisting}
 smooth position of p0=x0,y0 between p1=x1,y1 and p2=x2,y2,
 so that distance to p1 and p2 becomes equal
 and the chord length remains the same

\end{lstlisting}
\subsection{smooth2}
${}$
\begin{lstlisting}
 smooth vectos of X

\end{lstlisting}
\subsection{smooth\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{smooth\_parametric}
${}$
\begin{lstlisting}
 smooth a parametric function given in x-y coordinates
	matvec2x2(R,[dxc;dyc])

\end{lstlisting}
\subsection{smooth\_parametric2}
${}$
\begin{lstlisting}
 parametrically smooth the curve

\end{lstlisting}
\subsection{smooth\_with\_splines}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{smoothfft}
${}$
\begin{lstlisting}
 filter with fast fourier transform

\end{lstlisting}
\section{signal-processing/spectral-density}
\subsection{hex\_angular\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hex\_angular\_pdf\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hex\_angular\_pdf\_max2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_ar2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_area}
${}$
\begin{lstlisting}
 integrate the spectral density

\end{lstlisting}
\subsection{spectral\_density\_estimate\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_flat}
${}$
\begin{lstlisting}
 flat spectral density of a random vector woth iid elements

\end{lstlisting}
\subsection{spectral\_density\_forest}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_gausswin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_lorentzian}
${}$
\begin{lstlisting}
 lorentzian spectral density

\end{lstlisting}
\subsection{spectral\_density\_lorentzian\_max}
${}$
\begin{lstlisting}
 mode (maximum) of the lorentzian spectral density

\end{lstlisting}
\subsection{spectral\_density\_lorentzian\_max2par}
${}$
\begin{lstlisting}
 transform maximum of the lorentzian spectral density to its distribution parameters

\end{lstlisting}
\subsection{spectral\_density\_lorentzian\_scale}
${}$
\begin{lstlisting}
 normalization scale of the lorentzian spectral density

\end{lstlisting}
\subsection{spectral\_density\_maximum\_bias\_corrected}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_periodic\_additive\_noise}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_rectwin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_density\_wperiodic}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing}
\subsection{spectrogram}
${}$
\begin{lstlisting}
 spectrogram

\end{lstlisting}
\subsection{sum\_i\_lag}
${}$
\begin{lstlisting}
 sum of ar1 matrix with lag
 sum_i=1^n rho^|i-k|

\end{lstlisting}
\subsection{sum\_ii}
${}$
\begin{lstlisting}
 sum of ar1 matrix
 sum_i=1^n sum_j=1^n rho^|i-j|
 this is for the variance, take square root for the standard deviation factor

\end{lstlisting}
\subsection{sum\_ii\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{sum\_ij}
${}$
\begin{lstlisting}
 sum of ar1 matrix
 sum_{i=1}^n sum_{j=1}^m r^|i-j|

\end{lstlisting}
\subsection{sum\_ij\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{sum\_ij\_partial\_}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{sum\_multivar}
${}$
\begin{lstlisting}
 sum of matrix entries of bivariate ar1 process

\end{lstlisting}
\subsection{test\_acfar1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{tikhonov\_to\_ar1}
${}$
\begin{lstlisting}
 convert coefficient of the tikhonov regularization to correlatioon of the ar1 process

\end{lstlisting}
\subsection{trapwin}
${}$
\begin{lstlisting}
 trapezoidal filter window

\end{lstlisting}
\subsection{triwin}
${}$
\begin{lstlisting}
 triangular filter window

\end{lstlisting}
\subsection{triwin2}
${}$
\begin{lstlisting}
 triangular filter window

\end{lstlisting}
\subsection{tukeywin\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{varar1}
${}$
\begin{lstlisting}
 error variance of a single sample of a finite length ar1 process
 with respect to the mean, averaged over the population

\end{lstlisting}
\subsection{welch\_spectrogram}
${}$
\begin{lstlisting}
 welch spectrogram

\end{lstlisting}
\subsection{wfilt}
${}$
\begin{lstlisting}
 filter with window

\end{lstlisting}
\subsection{winbandpass}
${}$
\begin{lstlisting}
 filter with bandpass

\end{lstlisting}
\section{signal-processing/windows}
\subsection{circwin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{danielle\_window}
${}$
\begin{lstlisting}
 danielle fourier window

\end{lstlisting}
\subsection{gausswin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gausswin1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gausswin2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{radial\_window}
${}$
\begin{lstlisting}
 radial filter window in the 2d-frequency domain

\end{lstlisting}
\subsection{range\_window}
${}$
\begin{lstlisting}
 range of values within a certain range of indices (window)

\end{lstlisting}
\subsection{rectwin\_cutoff\_frequency}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{std\_window}
${}$
\begin{lstlisting}
 moving block standard deviation

\end{lstlisting}
\subsection{window2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{window\_make\_odd}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{signal-processing}
\subsection{winfilt0}
${}$
\begin{lstlisting}
 filter with window

\end{lstlisting}
\subsection{winlength}
${}$
\begin{lstlisting}
 window length for desired cutoff frequency
 power at fc is halved
 H(wf) = 1/sqrt(2) H(f)
 if the filter window were used as a low pass filter
 note: the user should prefer a windowed ideal low pass filter
 TODO, relate this to DOF

\end{lstlisting}
\subsection{wmeanfilt}
${}$
\begin{lstlisting}
 mean filter with window

\end{lstlisting}
\subsection{wmedfilt}
${}$
\begin{lstlisting}
 median filter with window

\end{lstlisting}
\subsection{wordfilt}
${}$
\begin{lstlisting}
 weighted order filter

\end{lstlisting}
\subsection{wordfilt\_edgeworth}
${}$
\begin{lstlisting}
 weighed order filter

\end{lstlisting}
\subsection{wrapphase}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{xar1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{xcorr\_man}
${}$
\begin{lstlisting}
 cross correlation of two sampled ar1 processes

\end{lstlisting}
\section{sorting}
\subsection{sort2}
${}$
\begin{lstlisting}
 sort two numbers

\end{lstlisting}
\subsection{sort2d}
${}$
\begin{lstlisting}
 sort elements of matrix in X
 returns row and column index of sorted values

\end{lstlisting}
\section{spatial-pattern-analysis/@Spatial\_Pattern}
\subsection{Spatial\_Pattern}
${}$
\begin{lstlisting}
 class for analysis of remotely sensed and model generated vegetation patterns

\end{lstlisting}
\subsection{analyze\_grid}
${}$
\begin{lstlisting}
 analyze a 2D spatial pattern, estimate regularity and test for periodicity

\end{lstlisting}
\subsection{analyze\_transect}
${}$
\begin{lstlisting}
 analyze 1D transect through a spatial pattern,
 either remotely sensed or model generated

\end{lstlisting}
\subsection{fit\_parametric\_densities}
${}$
\begin{lstlisting}
 fit parametric spectral densities to the empirical density

\end{lstlisting}
\subsection{imread}
${}$
\begin{lstlisting}
 read an image file containing a pattern, mask and geospatial data

\end{lstlisting}
\subsection{plot}
${}$
\begin{lstlisting}
 plot the pattern or densities 

\end{lstlisting}
\subsection{plot\_transect}
${}$
\begin{lstlisting}
 plot 1D pattern

\end{lstlisting}
\subsection{report}
${}$
\begin{lstlisting}
 report statistics of analysis

\end{lstlisting}
\subsection{resample\_functions}
${}$
\begin{lstlisting}
 resample empirical densities to a comman grid

\end{lstlisting}
\subsection{tabulate}
${}$
\begin{lstlisting}
 summarize properties of multiple patterns in a single struct

\end{lstlisting}
\section{spatial-pattern-analysis}
\subsection{approximate\_ratio\_distribution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{banded\_pattern}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hexagonal\_pattern}
${}$
\begin{lstlisting}
 function [z, x, y, xx, yy, xe, ye] = hexagonal_pattern(fc,n,L,angle0_rad,scale,sbm,p,q)

 spot pattern of unit amplitude
 output : z : pattern
	   x : x-coordinate
	   y : y-coordinate
 
 Note : z_gap = 1 - z_spot

\end{lstlisting}
\subsection{patch\_size\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{patch\_size\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{reconstruct\_isotropic\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{separate\_isotropic\_from\_anisotropic\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{suppress\_low\_frequency\_lobe}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{spatial-statistics}
\subsection{average\_corr\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{special-functions}
\subsection{bessel\_sphere}
${}$
\begin{lstlisting}
 spherical Bessel function of the first kind

\end{lstlisting}
\subsection{besseliln\_large\_x}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{beta\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{betainc\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{digamma\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{exp10}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hankel\_sphere}
${}$
\begin{lstlisting}
 spherical Hankel function for the far field (incident plane wave)
 first kind

\end{lstlisting}
\subsection{hermite}
${}$
\begin{lstlisting}
 probabilistic's hermite polynomial by recurrence relation

 input :
 n : order
 x : value

 output:
 f : H_n(x)
 df : d/dx H_n(x)


\end{lstlisting}
\subsection{lambertw\_numeric}
${}$
\begin{lstlisting}
 lambert-w function

\end{lstlisting}
\subsection{legendre\_man}
${}$
\begin{lstlisting}
 legendre polynomials

\end{lstlisting}
\subsection{neumann\_sphere}
${}$
\begin{lstlisting}
 spherical Neumann function
 Bessel function of the second kind

\end{lstlisting}
\section{statistics}
\subsection{atan\_s2}
${}$
\begin{lstlisting}
 stadard deviation of the arcus tangens by means of taylor expansion

\end{lstlisting}
\subsection{binomial}
${}$
\begin{lstlisting}
 generalized binomial coefficient, working for non-integer arguments,
 in contrast to the matlab buildin function nchoosek

\end{lstlisting}
\subsection{coefficient\_of\_determination}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{conditional\_expectation\_normal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{correlation\_confidence\_pearson}
${}$
\begin{lstlisting}
 confience intervals of the correlation coefficient
 c.f. Fischer 1921

\end{lstlisting}
\section{statistics/distributions}
\subsection{PDF}
${}$
\begin{lstlisting}
 class for quasi-distributions from a set of sampling points

\end{lstlisting}
\section{statistics/distributions/beta}
\subsection{beta\_kurt}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{beta\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{beta\_moment2param}
${}$
\begin{lstlisting}
 transform central moments (mean and sd) to parameters of the beta function

\end{lstlisting}
\subsection{beta\_skew}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{beta\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/bivariate-normal}
\subsection{binorm\_separation\_coefficient}
${}$
\begin{lstlisting}
 separation coefficient of a bimodal normal distribution

\end{lstlisting}
\subsection{binormcdf}
${}$
\begin{lstlisting}
 bio-modal gaussian distribution

\end{lstlisting}
\subsection{binormfit}
${}$
\begin{lstlisting}
 fit sum of to normal distribution to a histogram

\end{lstlisting}
\subsection{binormpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/chi2}
\subsection{chi2\_kurt}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{chi2\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{chi2\_skew}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{chi2\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/circular-normal}
\subsection{wnormpdf}
${}$
\begin{lstlisting}
 wrapped normal distribution to the unit circle
 c.f. stephens

\end{lstlisting}
\section{statistics/distributions}
\subsection{edgeworth\_cdf}
${}$
\begin{lstlisting}
 edgeworth expansion of an unknown cumulative distribution
 with mean mu, standard deviation sigma, and third and fourth cumulants
 c.f. Rao 2010

\end{lstlisting}
\subsection{edgeworth\_pdf}
${}$
\begin{lstlisting}

 probability density of and unknown distribution
 with mean mu, standard deviation sigma, and third and fourth cumulants
 c.f. Rao 2010

\end{lstlisting}
\subsection{exppdf\_max2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/fisher}
\subsection{fisher\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fisher\_moment2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{fisher\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/gamma}
\subsection{gamma\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gamma\_mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gamma\_mode2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gamma\_moment2param}
${}$
\begin{lstlisting}
 transform modes (mu,sd) to parameters of the gamma distribution

\end{lstlisting}
\subsection{gamma\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gamma\_stirling}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gampdf\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{generalized\_gamma\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/hotelling-t2}
\subsection{t2cdf}
${}$
\begin{lstlisting}
 Hotelling's T-squared cumulative distribution

\end{lstlisting}
\subsection{t2inv}
${}$
\begin{lstlisting}
 inverse of Hotelling's T-squared cumulative distribution

\end{lstlisting}
\section{statistics/distributions/kurt-normal}
\subsection{kurtncdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kurtnpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/log-triangular}
\subsection{logtrialtcdf}
${}$
\begin{lstlisting}
 pdf of a logarithmic triangular distribution

\end{lstlisting}
\subsection{logtrialtinv}
${}$
\begin{lstlisting}
 inverse of the logarithmic triangular distribution
 = (d F log(a) log(b) + a log(b) - b log(a) - d F log(a) log(c) - a log(c) + d F log(b) log(c) + b log(c) - d F log^2(b))/((log(a) - log(b)) W((a^(-1/(log(a) - log(b))) (b^(-log(c)/log(a) - 1/log(a)) c)^(-log(a)/(log(a) - log(b))) (-d F log^2(b) + a log(b) + d F log(a) log(b) + d F log(c) log(b) - b log(a) - a log(c) + b log(c) - d F log(a) log(c)))/(log(a) - log(b))))
x = (d F log(a) log(b) + a log(b) - b log(a) - d F log(a) log(c) - a log(c) + d F log(b) log(c) + b log(c) - d F log^2(b))/((log(a) - log(b)) W((a^(-1/(log(a) - log(b))) (b^(-log(c)/log(a) - 1/log(a)) c)^(-log(a)/(log(a) - log(b))) (-d F log^2(b) + a log(b) + d F log(a) log(b) + d F log(c) log(b) - b log(a) - a log(c) + b log(c) - d F log(a) log(c)))/(log(a) - log(b))))

\end{lstlisting}
\subsection{logtrialtmean}
${}$
\begin{lstlisting}
 mean of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtrialtpdf}
${}$
\begin{lstlisting}
 density of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtrialtrnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{logtricdf}
${}$
\begin{lstlisting}
 cumulative distribution of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtriinv}
${}$
\begin{lstlisting}
 invere of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtrimean}
${}$
\begin{lstlisting}
 mean of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtripdf}
${}$
\begin{lstlisting}
 probability density of the logarithmic triangular distribution

\end{lstlisting}
\subsection{logtrirnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/log-uniform}
\subsection{logu\_median}
${}$
\begin{lstlisting}
 median of the log-uniform distribution

\end{lstlisting}
\subsection{logucdf}
${}$
\begin{lstlisting}
 probability density of the logarithmic uniform distribution

\end{lstlisting}
\subsection{logucm}
${}$
\begin{lstlisting}
 central moments of the log-uniform distribution

\end{lstlisting}
\subsection{loguinv}
${}$
\begin{lstlisting}
 inverse of the log-uniform distribution  

\end{lstlisting}
\subsection{logumean}
${}$
\begin{lstlisting}
 mean of the log-uniform distribution

\end{lstlisting}
\subsection{logupdf}
${}$
\begin{lstlisting}
 pdf of the log uniform distribution

\end{lstlisting}
\subsection{logurnd}
${}$
\begin{lstlisting}
 random numbers following a log-uniform distribution

\end{lstlisting}
\subsection{loguvar}
${}$
\begin{lstlisting}
 variance of the log-uniform distribution

\end{lstlisting}
\section{statistics/distributions/loglog}
\subsection{loglogpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/lognormal}
\subsection{logn\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{logn\_mode}
${}$
\begin{lstlisting}
 mode (maximum) of the log-normal density

\end{lstlisting}
\subsection{logn\_mode2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{logn\_moment2param}
${}$
\begin{lstlisting}
 transform the mode (mu,sd) to parameters of the log normal distribution

\end{lstlisting}
\subsection{logn\_param2moment}
${}$
\begin{lstlisting}
 transform parameters to mode (mu, sd) for the log normal distribution

\end{lstlisting}
\subsection{logn\_skewness}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{logn\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lognpdf\_}
${}$
\begin{lstlisting}
 log normal distribution called by modes rather than parameters

\end{lstlisting}
\subsection{lognpdf\_entropy}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/logskew}
\subsection{logskewcdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{logskewpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/mise}
\subsection{misespdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions}
\subsection{ncx2\_moment2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/normal}
\subsection{normpdf\_entropy}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/passes}
\subsection{bandpass1d\_continuous\_pdf}
${}$
\begin{lstlisting}

 function [S_bp,Sc] = spectral_density_bandpass_continous(fx,fc,order,normalize,pp)

 output :
 S_bp : spectral density of the bandpass filter in continuos space
     limit case of the discrete bandpass for dx -> 0
 Sc   : scale factor to normalize area to 1, if noramlize = true

 input :
 f     : frequency (abszissa)
 fc    : central freqeuncy, location of maximum on abszissa
 order : number of times filter is applied iteratively, not necessarily integer
 normalize : normalize area under curve int_0^inf S(f) df = 1, if not maximum S(fc) = 1
 pp    : powers for recombination of the lowpass filter 

\end{lstlisting}
\subsection{bandpass1d\_continuous\_pdf\_max}
${}$
\begin{lstlisting}
 maximum of the bandpass spectral density

\end{lstlisting}
\subsection{bandpass1d\_continuous\_pdf\_max2par}
${}$
\begin{lstlisting}
 transform mode (maxima) of the bandpass spectral density into the paramter
 of the underlying distribution 

\end{lstlisting}
\subsection{bandpass1d\_continuous\_pdf\_scale}
${}$
\begin{lstlisting}
 normaliztation scale of the spatial bandpass density

\end{lstlisting}
\subsection{bandpass1d\_discrete\_pdf}
${}$
\begin{lstlisting}
 spectral density of the discrete spatial (two-sided) bandpass filter

\end{lstlisting}
\subsection{bandpass2d\_discrete\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_pdf\_mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{bandpass2d\_pdf\_mode2par}
${}$
\begin{lstlisting}
 transform mode (maxima) of the bandpass spectral density into the paramter
 of the underlying distribution 

\end{lstlisting}
\subsection{bandpass2d\_pdf\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass1d\_discrete\_cos\_pdf}
${}$
\begin{lstlisting}
 consine shaped spectral density of a highpass filter

\end{lstlisting}
\subsection{highpass1d\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass2d\_discrete\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{highpass2d\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass1d\_continuous\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass1d\_continuous\_pdf\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass1d\_discrete\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass1d\_one\_sided\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_discrete\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{lowpass2d\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions}
\subsection{pdfsample}
${}$
\begin{lstlisting}
 pdf from sample distribution
 Note: better use kernal density estimates

\end{lstlisting}
\section{statistics/distributions/phase\_drift}
\subsection{phase\_drift\_acf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_acf\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_acf\_across}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_cdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_inv}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_patch\_size\_distribution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf}
${}$
\begin{lstlisting}
 spectral density of a fourier series where the phase undergoes brownian motion
 with standard deviation s per unit distance

\end{lstlisting}
\subsection{phase\_drift\_pdf\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_across}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_across\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_across\_max2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_across\_mode2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_mode}
${}$
\begin{lstlisting}
 mode (maximum) of the spectral density of the fourier series with brownian phase

\end{lstlisting}
\subsection{phase\_drift\_pdf\_mode2par}
${}$
\begin{lstlisting}
 transform mode to parameters of the brownian phase spectral density

\end{lstlisting}
\subsection{phase\_drift\_pdf\_reg2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phase\_drift\_pdf\_scale}
${}$
\begin{lstlisting}
 normalization scale of the brownian phase spectral density

\end{lstlisting}
\section{statistics/distributions/skew-normal}
\subsection{skew\_generalized\_normal\_fit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skew\_generalized\_normpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewcdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewparam\_to\_central\_moments}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewpdf}
${}$
\begin{lstlisting}
 skew-normal distribution
 c.f. Azzalini 1985

\end{lstlisting}
\subsection{skewpdf\_entropy}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/distributions/triangular}
\subsection{tricdf}
${}$
\begin{lstlisting}
 cumulative distribution of the log-triangular distribution

\end{lstlisting}
\subsection{triinv}
${}$
\begin{lstlisting}
 inverse of the triangular distribution

\end{lstlisting}
\subsection{trimedian}
${}$
\begin{lstlisting}
 median of the triangular distribution

\end{lstlisting}
\subsection{tripdf}
${}$
\begin{lstlisting}
 probability density of the triangular distribution

\end{lstlisting}
\subsection{trirnd}
${}$
\begin{lstlisting}
 random numbers of the triangular distribution

\end{lstlisting}
\section{statistics/distributions/wrapped-normal}
\subsection{normpdf\_wrapped}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{normpdf\_wrapped\_mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{normpdf\_wrapped\_mode2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics}
\subsection{error\_propagation\_fraction}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{error\_propagation\_product}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{example\_standard\_error\_of\_sample\_quantiles}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{f\_var\_finite}
${}$
\begin{lstlisting}
 reduction of variance when sampling from a finite population
 without replacement

\end{lstlisting}
\subsection{gaussfit3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{gaussfit\_quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{geoserr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{geostd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{hodges\_lehmann\_correlation}
${}$
\begin{lstlisting}
 hodges_lehmann correlatoon coefficient
 c.f. Shamos 1976
 c.f. Bickel and Lehmann 1976
 c.f. rousseeuw 1993
 c.f. Shevlyakov 2011

\end{lstlisting}
\subsection{hodges\_lehmann\_dispersion}
${}$
\begin{lstlisting}
 dispersion determined by the hodges lehman method
 asymptotic efficiency of dispersion estimates:
 standard deviation:      E(s - hat s)/s = 2/sqrt(2 n) ~ 0.707/sqrt(n)			(100%)
 hodges lehmann dispersion E(s-\hat s)/s = (pi/3)^2 /(sqrt(2 n)) ~ 0.775/sqrt(n)	(91%)
 mad                      E(s-\hat s)/s ~ 1.17 s/sqrt(n)				(60%) 					
 c.f. Shamos 1976
 c.f. Bickel and Lehmann 1976
 c.f. rousseeuw 1993
 nb: rousseeuw uses the 25th percentile, which is more efficient for small sample sizes

\end{lstlisting}
\section{statistics/information-theory}
\subsection{akaike\_information\_criterion}
${}$
\begin{lstlisting}
 akaike information criterion

 serr : rmse of model prediction
 n : effective sample size
 k : number of parameters

 c.f. akaike (1974)
 c.f. sugiura 1978

\end{lstlisting}
\subsection{bayesian\_information\_criterion}
${}$
\begin{lstlisting}
 bayesian information criterion

\end{lstlisting}
\section{statistics}
\subsection{jackknife\_block}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{kurtosis\_bias\_corrected}
${}$
\begin{lstlisting}
 bias corrected kurtosis

\end{lstlisting}
\subsection{limit}
${}$
\begin{lstlisting}
 limit a by lower and upper bound

\end{lstlisting}
\subsection{logfactorial}
${}$
\begin{lstlisting}
 approximate log of the factorial

\end{lstlisting}
\subsection{lognfit\_quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{max\_exprnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{maxnnormals}
${}$
\begin{lstlisting}
 expected maximum of n normal variables
 c.f. Wolperts
 this is the median, not the mean of the maximum!
 see median of gumbel

\end{lstlisting}
\subsection{mean\_angle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mean\_max\_n}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mean\_min\_n}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{midrange}
${}$
\begin{lstlisting}
 mid range of columns of X

\end{lstlisting}
\subsection{minavg}
${}$
\begin{lstlisting}
 solution of the minimum variance problem
 minimise the variance of the weighted sum of n-independent
 random variables with equal mean and individual variance

\end{lstlisting}
\subsection{mode\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/moment-statistics}
\subsection{autocorr\_man3}
${}$
\begin{lstlisting}
 autoccorrelation of the columns of X 

\end{lstlisting}
\subsection{autocorr\_man4}
${}$
\begin{lstlisting}
 autocorrelation for x if x is a vector, or indivvidually for the 
 columns of x if x is a matrix

 c.f. box jenkins 2008 eq. 2.1.12

 Note that it is faster to compute the acf in frequency space
 as done in the matlab internal function

\end{lstlisting}
\subsection{autocorr\_man5}
${}$
\begin{lstlisting}
 autocorrellation of the columns of X

\end{lstlisting}
\subsection{blockserr}
${}$
\begin{lstlisting}
 estimate the standard error of potetially sequentilly correlated data
 by blocking
 block length should be sufficiently larger than correlation length
 and sufficiently smaller than data length
 this uses a sliding block approach, which reduces the variation of the error estimate

\end{lstlisting}
\subsection{comoment}
${}$
\begin{lstlisting}
 non-central higher order moments of the multivariate normal distribution

 c.f. Moments and cumulants of the multivariate real and complex Gaussian distributions
 
 note : there seem to be some typos in the original paper, 
	for x^4 cii^2, the square seems to be missing
 mu : nx1 mean vector
 C  : nxn covariance matrix
 k  : nx1 powers of variables in moments

\end{lstlisting}
\subsection{corr\_man}
${}$
\begin{lstlisting}
 correlation of two vectors

\end{lstlisting}
\subsection{cov\_man}
${}$
\begin{lstlisting}
 covariance matrix of two vectors

\end{lstlisting}
\subsection{dof}
${}$
\begin{lstlisting}
 mininum number of support points
 for a polynomial of degree order in dim dimensions

\end{lstlisting}
\subsection{edgeworth\_quantile}
${}$
\begin{lstlisting}
 inverse edgeworth expansion
 c.f. cornis fisher 1937
 c.f. Rao 2010
 c.f. 2.50 in hall
 CHERNOZHUKOV 3.3

\end{lstlisting}
\subsection{effective\_sample\_size}
${}$
\begin{lstlisting}
 effective sample size of the weighted mean of uncorrelated data
 c.f. Kish

\end{lstlisting}
\subsection{f\_correlation}
${}$
\begin{lstlisting}
 correction factor for standard error of the mean of n ar1-correlated iid samples

\end{lstlisting}
\subsection{f\_finite}
${}$
\begin{lstlisting}
 reduction factor of standard error for sampling from a finite distribution
 without replacement

\end{lstlisting}
\subsection{lmean}
${}$
\begin{lstlisting}
 mean of x.^l, not of abs

\end{lstlisting}
\subsection{lmoment}
${}$
\begin{lstlisting}
 l-moment of vector x

\end{lstlisting}
\subsection{maskmean}
${}$
\begin{lstlisting}
 mean of the masked values of X

\end{lstlisting}
\subsection{masknanmean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{mean1}
${}$
\begin{lstlisting}
 mean of x

\end{lstlisting}
\subsection{mean\_man}
${}$
\begin{lstlisting}
 mean and standard error of X

\end{lstlisting}
\subsection{mse}
${}$
\begin{lstlisting}
 mean squared error of residual vector res
 this is de-facto the std for an unbiased residual

\end{lstlisting}
\subsection{nanautocorr\_man1}
${}$
\begin{lstlisting}
 autocorrelation of a vector with nan-values

\end{lstlisting}
\subsection{nanautocorr\_man2}
${}$
\begin{lstlisting}
 autocorrelation of a vector with nan-values

\end{lstlisting}
\subsection{nanautocorr\_man4}
${}$
\begin{lstlisting}
 compute autocorrelation for x if x is a vector, or indivvidually for the 
 columns of x if x is a matrix
 box jenkins 2008 eq. 2.1.12
 TODO nan is problematic!
 Note that it is faster to compute the acf in frequency space
 as done in the matlab internal function

\end{lstlisting}
\subsection{nancorr}
${}$
\begin{lstlisting}
 (co)-correlation matrix when samples a NaN

\end{lstlisting}
\subsection{nancumsum}
${}$
\begin{lstlisting}
 cumulative sum, setting nan values to zero

\end{lstlisting}
\subsection{nanlmean}
${}$
\begin{lstlisting}
 mean of the l-th power of the absolute value of x

\end{lstlisting}
\subsection{nanr2}
${}$
\begin{lstlisting}
 coefficient of determination when samples are invalid

\end{lstlisting}
\subsection{nanrms}
${}$
\begin{lstlisting}
 root mean square value when sample contains nan-values

\end{lstlisting}
\subsection{nanrmse}
${}$
\begin{lstlisting}
 root mean square error from vector of residuals
 this is de-facto the std for an unbiased residual

\end{lstlisting}
\subsection{nanserr}
${}$
\begin{lstlisting}
 standard error of x with respect to mean when x contains nan values

\end{lstlisting}
\subsection{nanwmean}
${}$
\begin{lstlisting}
 weighted mean
 min_x sum w (x-mu)^2 => mu = sum(wx)/sum(w)
 varargin can be dim
 function [mu serr] = nanwmean(w,x)

\end{lstlisting}
\subsection{nanwstd}
${}$
\begin{lstlisting}
 weighed standard deviation

\end{lstlisting}
\subsection{nanwvar}
${}$
\begin{lstlisting}
 weighted variance of columns, corrected for degrees of freedom (bessel)

 s^2 = sum(w*(x-sum(wx)/sum(w))^2)/sum(w)

\end{lstlisting}
\subsection{nanxcorr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{pearson}
${}$
\begin{lstlisting}
 pearson correlation coefficient

\end{lstlisting}
\subsection{pearson\_to\_kendall}
${}$
\begin{lstlisting}
 conversion of pearson to kendall correlation coefficient
 c.f. Kruskal 1958

\end{lstlisting}
\subsection{pool\_samples}
${}$
\begin{lstlisting}
 pooled mean and standard deviation of several groups of different size, mean and standard deviation

\end{lstlisting}
\subsection{qmean}
${}$
\begin{lstlisting}
 trimmed mean

\end{lstlisting}
\subsection{range\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{rmse\_}
${}$
\begin{lstlisting}
 root mean square error computed from a residual vector
 this is de-facto the std for an unbiased residual

\end{lstlisting}
\subsection{serr}
${}$
\begin{lstlisting}
 standard error of the mean of a set of uncorrelated samples

\end{lstlisting}
\subsection{serr1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_qskew}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_qstd\_qskew\_optimal\_p}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{wautocorr}
${}$
\begin{lstlisting}
 autocorrelation for x if x is a vector, or indivvidually for the 
 columns of x if x is a matrix
 samples can be weighted

 c.f. box jenkins 2008 eq. 2.1.12

 c.f. autocorr_man4

 Note that it is faster to compute the acf in frequency space
 as done in the matlab internal function

\end{lstlisting}
\subsection{wcorr}
${}$
\begin{lstlisting}
 correlation of two vectors when samples are weighted

\end{lstlisting}
\subsection{wcov}
${}$
\begin{lstlisting}
 covariance of two vectors when samples are weighted

\end{lstlisting}
\subsection{wdof}
${}$
\begin{lstlisting}
 effective degrees of freedom for weighted samples

\end{lstlisting}
\subsection{wkurt}
${}$
\begin{lstlisting}
 kurtosis with weighted samples

\end{lstlisting}
\subsection{wmean}
${}$
\begin{lstlisting}
 weighted mean

 min_x sum w (x-mu)^2 => mu = sum(wx)/sum(w)

 varargin can be dim
 function [mu serr] = wmean(w,x)

\end{lstlisting}
\subsection{wrms}
${}$
\begin{lstlisting}
 weighted root mean square

\end{lstlisting}
\subsection{wserr}
${}$
\begin{lstlisting}
 weighted root mean square error

\end{lstlisting}
\subsection{wskew}
${}$
\begin{lstlisting}
 skewness of a weighted set of samples
 function sk = wskew(w,x)

\end{lstlisting}
\subsection{wstd}
${}$
\begin{lstlisting}
 weighed standard deviation

\end{lstlisting}
\subsection{wvar}
${}$
\begin{lstlisting}
 weighted variance of columns, corrected for degrees of freedom (bessel)
 variance of the weighted sample mean of samples with same mean (but not necessarily same variance)
 s^2 = sum (w^2(x-sum(wx)^2))

 s2_mu : error of mean, s2_mu : sd of prediction

\end{lstlisting}
\section{statistics}
\subsection{nangeomean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{nangeostd}
${}$
\begin{lstlisting}
 geometric standard deviation ignoring nan-values

\end{lstlisting}
\section{statistics/nonparametric-statistics}
\subsection{kernel1d}
${}$
\begin{lstlisting}
 X   : ouput x axis bins
 xi  : samples along x
 m   : number of bins in X
 fun : kernel function
 pdf : propability density of xi

\end{lstlisting}
\subsection{kernel2d}
${}$
\begin{lstlisting}
 kernel density estimate in two dimensions

\end{lstlisting}
\section{statistics}
\subsection{normmoment}
${}$
\begin{lstlisting}
 expected norm of x.^n, when values x in x are iid normal with mu and sigma

\end{lstlisting}
\subsection{normpdf2}
${}$
\begin{lstlisting}
 pdf of the bivariate normal distribution

\end{lstlisting}
\section{statistics/order-statistics}
\subsection{hodges\_lehmann\_location}
${}$
\begin{lstlisting}
 hodges lehman location estimator

 Asymptotic rms efficency of location estimte:
      mean:          1 s/sqrt(n)
      hodges lehman: sqrt(pi/3)*s ~ 1.0233 s/sqrt(n)
      median:        pi/2 s/sqrt(n) ~ 1.25 s / sqrt(n)

\end{lstlisting}
\subsection{kendall}
${}$
\begin{lstlisting}
 kendall correlation coefficient

\end{lstlisting}
\subsection{kendall\_to\_pearson}
${}$
\begin{lstlisting}
 convert kendall rank correlation coefficient to the person product moment
 correlation coefficient

 c.f. Kruskal, 1958, p. 823

\end{lstlisting}
\subsection{mad2sd}
${}$
\begin{lstlisting}
 transform median absolute deviation to standard deviation
 for normal distributed values

\end{lstlisting}
\subsection{madcorr}
${}$
\begin{lstlisting}
 proxy correlation by median absolute deviation

\end{lstlisting}
\subsection{median2\_holder}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{median\_ci}
${}$
\begin{lstlisting}
 median and its confidence intervals under assumption of normality
 se_me = sqrt(1/2 pi) 1.25331 * sd/sqrt(n)

\end{lstlisting}
\subsection{median\_man}
${}$
\begin{lstlisting}
 median and confidence intervals
 c is a P value for the confidence interval,
 default is 0.95 (2-sigma)
 median of the colums of X

\end{lstlisting}
\subsection{mediani}
${}$
\begin{lstlisting}
 index of median, if median is not unique, any of the values is chosen

\end{lstlisting}
\subsection{nanmadcorr}
${}$
\begin{lstlisting}
 proxy correlation by median absolute deviation

\end{lstlisting}
\subsection{nanwmedian}
${}$
\begin{lstlisting}
 weighted median, skips nan-values

\end{lstlisting}
\subsection{nanwquantile}
${}$
\begin{lstlisting}
 weighted quantile, skips nan values 

\end{lstlisting}
\subsection{oja\_median}
${}$
\begin{lstlisting}
 two dimensional oja median
 note: the multivariate median is not unique

 oja 1983, for extension to multivariate function, see chaudhri

\end{lstlisting}
\subsection{qkurtosis}
${}$
\begin{lstlisting}
 kurosis computed for quantiles

 Note : this is a measurement of shape-tailedness and yields the same value for the
        normal distribution as "kurtosis"
        However, this is a separate statistic and hence requires different
        methods for calculating P-values and hypothesis testing

\end{lstlisting}
\subsection{qmoments}
${}$
\begin{lstlisting}
 moments estimated from quantiles

\end{lstlisting}
\subsection{qskew}
${}$
\begin{lstlisting}
 skewness estimated from quantiles

 Note : this is a measurement of shape-symmetry and yields the same value for the
        skew-normal distribution as "skewness"
        However, this is an own statistic and hence requires different
        methods for calculating P-values and hypothesis testing

\end{lstlisting}
\subsection{qskewq}
${}$
\begin{lstlisting}
 skewness estimated by quantiles

\end{lstlisting}
\subsection{qstdq}
${}$
\begin{lstlisting}
 proxy standard deviation determined by quantiles

\end{lstlisting}
\subsection{quantile1\_optimisation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantile2\_breckling}
${}$
\begin{lstlisting}
 qunatile regression

\end{lstlisting}
\subsection{quantile2\_chaudhuri}
${}$
\begin{lstlisting}
 quantile regression

\end{lstlisting}
\subsection{quantile2\_projected}
${}$
\begin{lstlisting}
 quantile in two dimensions

\end{lstlisting}
\subsection{quantile2\_projected2}
${}$
\begin{lstlisting}
 spatial qunatile for chosen direction

\end{lstlisting}
\subsection{quantile\_envelope}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantile\_regression\_simple}
${}$
\begin{lstlisting}
 simple quantile regression

\end{lstlisting}
\subsection{ranking}
${}$
\begin{lstlisting}
 ranking for spearman statistics

\end{lstlisting}
\subsection{spatial\_median}
${}$
\begin{lstlisting}
 c.f. Oja 2008
 is this the same as the oja simplex median (c.f. small 1990)?

\end{lstlisting}
\subsection{spatial\_quantile}
${}$
\begin{lstlisting}
 spatial quantile

\end{lstlisting}
\subsection{spatial\_quantile2}
${}$
\begin{lstlisting}
 spatial quantile

\end{lstlisting}
\subsection{spatial\_quantile3}
${}$
\begin{lstlisting}
 spatial quantile

\end{lstlisting}
\subsection{spatial\_rank}
${}$
\begin{lstlisting}
 unsigned rank

\end{lstlisting}
\subsection{spatial\_sign}
${}$
\begin{lstlisting}
 spatial sign

\end{lstlisting}
\subsection{spatial\_signed\_rank}
${}$
\begin{lstlisting}
 signed rank
 Note: this is only a true rank if X is normal with zero mean, abitrary variance

\end{lstlisting}
\subsection{spearman}
${}$
\begin{lstlisting}
 spearman's product moment coefficient

\end{lstlisting}
\subsection{spearman\_rank}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spearman\_to\_pearson}
${}$
\begin{lstlisting}
 conversion of spearman rank to person product moment correlation coefficient

\end{lstlisting}
\subsection{wmedian}
${}$
\begin{lstlisting}
 weighted median

\end{lstlisting}
\subsection{wquantile}
${}$
\begin{lstlisting}
 weighted quantile

\end{lstlisting}
\section{statistics}
\subsection{qstd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantile\_extrap}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{quantile\_sin}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/random-number-generation}
\subsection{laplacernd}
${}$
\begin{lstlisting}
 random number of laplace distribution

\end{lstlisting}
\subsection{randc}
${}$
\begin{lstlisting}
 correlate to correlated standard normally distributed vectors

\end{lstlisting}
\subsection{skewness2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewpdf\_central\_moments}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{skewrnd}
${}$
\begin{lstlisting}
 random numbers of the skew normal distribution

\end{lstlisting}
\section{statistics}
\subsection{range}
${}$
\begin{lstlisting}
 range and mid range of input

\end{lstlisting}
\subsection{resample\_with\_replacement}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{statistics/resampling-statistics/@Jackknife}
\subsection{Jackknife}
${}$
\begin{lstlisting}
 class for leave out 1 (delete 1) Jackknife estimates

 note 1 : the 1-delete jackknife does not yield consistend estimates for all functions,
        in particular it will perform poorly on robust estimation functions
        this is overcome by the d-delete jacknife, where d has to exceed the breakdown point
        of the estimating function, for example sqrt(n) for the median
        as this leads to unreasonably large number of repetitions, bootstrap
        is recommended for large sample cases (or blocking for sequential data)
 note 2 : as a linearisation, jackknife underestimates the error variance in case of 
          dependence in the data
 note 3 : studentisation and the leave out 1 jackknife are related
 note 4 : the double 1 sample jacknife performs iferior to the d1 jacknife

\end{lstlisting}
\subsection{estimated\_STATIC}
${}$
\begin{lstlisting}
 jacknife estimate of mean, bias and standard error
 theta0 : estimate from all samples
 thetad : set of estimates obtained by leaving out one data point each
          last dimension of theta is assumed to be the jackknife dimension

\end{lstlisting}
\subsection{matrix1\_STATIC}
${}$
\begin{lstlisting}
 matrix of estimation for leaving out two samples at a time

\end{lstlisting}
\subsection{matrix2}
${}$
\begin{lstlisting}
 matrix of estimations for jacknive with two samples left out

\end{lstlisting}
\section{statistics/resampling-statistics}
\subsection{block\_jackknife}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{jackknife\_moments}
${}$
\begin{lstlisting}
 moments determined by the jacknife

 func : function of interest on the samples (e.g. mean)
 A    : parameter matrix
        columns : parameters
        rows    : samples of the parameter sets
 d   : number of samples left out

\end{lstlisting}
\subsection{moving\_block\_jackknife}
${}$
\begin{lstlisting}

 blocked Jacknfife for autocorrelated data
 sliding block, statistically more efficient but computationally expensive
 note, number of blocks must be sufficiently large h ~ sqrt(n)? << n

\end{lstlisting}
\subsection{randblockserr}
${}$
\begin{lstlisting}
 standard error of sequentilly correlated data by blocking
 block length should be sufficiently larger than correlation length
 and sufficiently smaller than data length
 this uses a sliding block approach, which reduces the variation of the error estimate
 TODO this does not work, randomly picking samples does not reveal the correlation

\end{lstlisting}
\subsection{resample}
${}$
\begin{lstlisting}
 resample a vector and apply function to it

 TODO, should be with replacement

 n  : number of samples
 m  : number of subsamples
 cx : maximum number of combinations

\end{lstlisting}
\section{statistics}
\subsection{scale\_quantile\_sd}
${}$
\begin{lstlisting}
 scale factor for the standard deviation
 of the asymtpotic distibution of sample quantiles
 (for normal distribution)
 see cadwell, 1952

\end{lstlisting}
\subsection{sd\_sample\_quantiles}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spatialrnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{trimmed\_mean}
${}$
\begin{lstlisting}
 trimmed mean

\end{lstlisting}
\subsection{ttest2\_man}
${}$
\begin{lstlisting}
 two-sample t-test
 here posix return value standard: h = 0 accepted, h = 1 failed
 note: the matlab logic is inverse : h = 1 accepted, h = 0 failed
 two sided univariate t-test

\end{lstlisting}
\subsection{ttest\_man}
${}$
\begin{lstlisting}
 two-sample t-test
 unequal sample size
 equal variance

\end{lstlisting}
\subsection{ttest\_paired}
${}$
\begin{lstlisting}
 paired t-test
 unequal sample size
 equal variance
 more powerfull than unpaired test, as long as correlation between x1 and x2 > 0

\end{lstlisting}
\subsection{uniformnpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{wgeomean}
${}$
\begin{lstlisting}
 weighted geometric mean
 function mu = wgeomean(w,x)

\end{lstlisting}
\subsection{wgeovar}
${}$
\begin{lstlisting}
 variance of the weighted geometric mean

\end{lstlisting}
\subsection{wharmean}
${}$
\begin{lstlisting}
 weighted harmonic mean

\end{lstlisting}
\subsection{wharstd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{wharvar}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{stochastic}
\subsection{brownian\_drift\_hitting\_probability}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_drift\_hitting\_probability2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_field}
${}$
\begin{lstlisting}
 simulate Fractional Brownian field on unit disk, with Hurst parameter 'H';
 Reference:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{lstlisting}
\subsection{brownian\_motion\_1d\_acf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_1d\_cov}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_1d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_1d\_fourier}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_1d\_interleave}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_1d\_laplacian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_cov}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_fft\_old}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_fourier}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_interleave}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_interleaving}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_kahunen}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_2d\_laplacian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{brownian\_motion\_with\_drift\_hitting\_probability}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ornstein\_uhlenbeck\_cov}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ornstein\_uhlenbeck\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ornstein\_uhlenbeck\_spectral\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{ornstein\_uhlenbeck\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{ternary\_diagram}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/finance}
\subsection{test\_gbb\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbb\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_mean\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_moment2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_moment2par\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_std}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gbm\_std\_entire\_series}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/fourier}
\subsection{test\_fourier\_freq2ind}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/master}
\subsection{dat\_test\_lanczos\_3d\_k\_20\_n\_40}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{poisson2d\_blk}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{qr\_implicit\_givens\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{spectral\_derivative\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_2d\_eigensolver\_hydrogen}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_2d\_refine}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_3d\_eigensolver\_hydrogen}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_FEM}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_Mesh\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_arnoldi}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_arpackc}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_assemble}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_assembly\_performance}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bc\_one\_sided}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_compare\_solvers}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_complete}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_convergence}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_convergence\_b}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_df\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eig\_algs}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eig\_inverse}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eigs\_lanczos}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eigs\_lanczos\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eigs\_lanczos\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_eigs\_lanczos\_performance}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fdm}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fdm\_d\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fdm\_spectral}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_1d\_higher\_order}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_2d\_adaptive}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_2d\_higher\_order}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_3d\_higher\_order}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_3d\_refine}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_b}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_derivative}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fem\_quadrature}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_final}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fix\_substitution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_forward}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_get\_sparse\_arrays}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_harmonic\_oscillator}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_high\_order\_fdm\_periodic\_bc}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_hydrogen\_wf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ichol}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_interpolation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_inverse\_problem}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_it\_vs\_exact}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_jama}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_jd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_jdqz}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lanczos\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lanczos\_biorthogonal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_laplacian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_laplacian\_non\_uniform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_laplacian\_simple}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mesh\_2d\_uniform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mesh\_2d\_uniform\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mesh\_circle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mesh\_generation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mesh\_interpolate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mg}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_minres\_recycle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_multigrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_nc}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_nonuniform\_symmetric}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_pde}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_permutation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_poison\_fem}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_polar}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_potential}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_powers}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_precondition}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_project\_rectangle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_qr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_quantum\_well}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_radial\_adaptive}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_radial\_confinement}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_radial\_fixes}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_refine\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_refine\_2d\_b}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_refine\_3d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_refine\_structural}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_regularisation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_round\_off}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_schrödinger\_potentials}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_uniform\_mesh}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_vargrid}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/signal-processing/autocorrelation}
\subsection{test\_acf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_acf\_bias}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_acfar1\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_acfar1\_3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_acfar1\_4}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_acfar2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1\_var\_factor}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1\_var\_factor\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1\_var\_mu\_single\_sample}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1\_var\_pop}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1\_var\_pop\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar1delay}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ar2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_acf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/signal-processing/passes}
\subsection{test\_bandpass2d\_ideal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lowpass1d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lowpass1d\_implicit}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lowpass2d\_anisotropic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lowpass2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lowpass2d\_rho}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/signal-processing/periodogram}
\subsection{test\_periodicity\_test\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periodogram\_bartlett\_se}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periodogram\_gauss}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periodogram\_radial}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periodogram\_test}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periodogram\_test\_periodicity\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_periogogram\_significance}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/signal-processing/spectral-density}
\subsection{test\_phase\_drift\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_across}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_across\_mode2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_mode2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_pdf\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_2d\_max2par}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_continuous}
${}$
\begin{lstlisting}
	title(sprintf('n %d L %g %g%%',[n,L,1e2*rmse(idx,jdx)]));

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_continuous\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_maximum}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bandpass\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bp\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_bp\_approx}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_flat}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_hp\_cos}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_lorentzian\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_lorentzian\_scale}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_lowpass}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_lowpass\_continuous}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_lowpass\_continuous\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectral\_density\_maxiumum\_bias\_corrected}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/signal-processing}
\subsection{test\_autocorrelation\_max}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_cdf\_bandpass\_continuous}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fit\_spectral\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phase\_drift\_cdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/spatial-pattern-analysis}
\subsection{test\_approximate\_ratio\_distribution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_approximate\_ratio\_quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_separate\_isotropic\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/distributions/gamma}
\subsection{test\_generalized\_gamma\_mean}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/distributions/log-uniform}
\subsection{test\_logurnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/distributions/passes}
\subsection{test\_bandpass2d\_pdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/distributions/skew-normal}
\subsection{test\_skew\_generalized\_normpdf}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/distributions}
\subsection{test\_normpdf\_wrapped}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics/moment-statistics}
\subsection{test\_wmean}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/statistics}
\subsection{test\_fisher\_moment2param}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gamma\_mode}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test/stochastics}
\subsection{test\_brownian\_surface}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{test}
\subsection{test\_S}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_advect\_analytic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_asymbp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bandpass2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bandwidth}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bartlett\_angle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bartlett\_distribution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bartlett\_expansion}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_beta}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_betainc}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_bivariate\_covariance\_term}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_drift\_hitting\_probability}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_drift\_hitting\_probability2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_motion\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_motion\_2d\_cov}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_motion\_2d\_fft}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_noise\_1d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_noise\_2d}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_brownian\_noise\_interleave}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_coherence}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_combined\_spectral\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_continuous\_fourier\_transform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_convexity}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_d2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_determine\_phase\_shift}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_diffuse\_analytic}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_diffusion\_matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ellipse}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_error\_propagation\_fraction}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_f}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_f2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fit\_2d\_spectral\_density}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier\_derivative}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier\_derivative\_1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier\_integral}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_fourier\_mask\_covariance\_matrix}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ft\_bp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gam}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gamma\_distribution}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gampdf\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gaussfit3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_gaussian\_flat}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_geoserr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_hexagonal\_pattern}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_iafrate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_implicit\_ode}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_imrotmat}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_integration}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ivp}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_jacobian}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lanczoswin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_laplacian\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_lognfit\_quantile}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ls\_perpendicular\_offset}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_madcorr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mask}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_max\_normal}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_moments}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_moments\_fourier\_power}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_mtimes3x3}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_noisy\_oscillator}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_nonperiodic\_pattern}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_normaliztation}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ols}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_parcorr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_positivity\_preserving}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_randar1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_randar1\_multivariate}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_randar2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_ratio\_distributions}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_sd\_rectwin}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spatialrnd}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_spectrum\_additivity}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_stationarity}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_stationarity2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_sum\_ij}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_sum\_multivar}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_trifilt1}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wautocorr}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wavelet\_transform}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_whittle}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_window}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wordfilt}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_xar1\_mid\_term}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{mathematics}
\begin{lstlisting}
mathematical functions of various kind

\end{lstlisting}
\subsection{trapezoidal\_fixed}
${}$
\begin{lstlisting}

\end{lstlisting}
\section{wavelet}
\subsection{contiuous\_wavelet\_transform}
${}$
\begin{lstlisting}
 continuous wavelet transform 
 follows "The Illustrated Wavelet Transform Handbook: Introductory Theory and ..."

\end{lstlisting}
\subsection{cwt\_man}
${}$
\begin{lstlisting}
 continuous fourier transform
 as of time of implmentation, the matlab interal cwt is affected by
 serious round-off errors and has issues with the scaling,
 which is not the case here

\end{lstlisting}
\subsection{cwt\_man2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{example\_wavelets}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{phasewrap}
${}$
\begin{lstlisting}
 wrap the phase to +/- pi

\end{lstlisting}
\subsection{test\_cwt\_man}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_phasewrap}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wavelet}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wavelet2}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wavelet\_analysis}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wavelet\_reconstruct}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{test\_wtc}
${}$
\begin{lstlisting}

\end{lstlisting}
\subsection{wavelet}
${}$
\begin{lstlisting}
 wavelet windows

\end{lstlisting}
\subsection{wavelet\_reconstruct}
${}$
\begin{lstlisting}
 iverses wavelet transform for single frequency
 (reconstruction of time series)
 n : window lengths in multiples of filter period 1/f0

\end{lstlisting}
\subsection{wavelet\_transform}
${}$
\begin{lstlisting}
 wavelet transform for single frequency
 n : window lengths in multiples of filter period 1/f0

\end{lstlisting}
\end{document}
